{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRylladAY9Aq"
      },
      "source": [
        "# Algorithms Homework 3\n",
        "\n",
        "**Assignment Overview:** In this assignment, we will complete the function `unconstrained_newton` which implements four Hessian options (exact, SR1 approximation, BFGS approximation, steepest descent) and three globalization strategies (none, line search, trust region). We will then compare 10 algorithm variations on three test problems.\n",
        "\n",
        "The best way to really learn the algorithms discussed in lecture is to implement them yourselves. Creating a function like `unconstrained_newton` from scratch takes a lot of time and comfort with Python. Instead, we will start with fairly complete version of `unconstrained_newton`. You will need to fill in the following details:\n",
        "* BFGS Hessian approximation\n",
        "* Backtracking line search with Armijo-Goldstein conditions\n",
        "* Trust region with Powell dogleg step\n",
        "\n",
        "This assignment could take a long time, especially if you are still learning Python. Recognizing this, we will try a new grading policy for this assignment.\n",
        "\n",
        "**Instructions**: To be eligible for full credit on the assignment, you need to:\n",
        "1. Complete all requested pseudocode\n",
        "2. Spend an honest **6 hours** (4 hours for CBE 40499) total working on Python implementation.\n",
        "3. Be sure to complete the **Feature Status** subsection.\n",
        "4. The (hopefully) correct results for the test cases are available online in this notebook. Answer the questions using these results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MDL0K4EY9At"
      },
      "source": [
        "## Pseudocode\n",
        "\n",
        "After reading through the entire assignment, please prepare pseudocode for the following functions/algorithms:\n",
        "1. SR1 update (Python code is provided. Going from code to pseudocode is good practice.)\n",
        "2. BFGS update\n",
        "3. Line search\n",
        "4. Trust region\n",
        "\n",
        "Please turn in this pseudocode via Gradescope.\n",
        "\n",
        "**Reminder:** pseudocode should not look like Python code copied to paper. Instead, pseudocode should clearly communicate the main steps of the algorithm with flow logic. Add lots of comments. It should not be programming language specific."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnFXOUAuY9Au"
      },
      "source": [
        "## Unconstrained NLP Algorithm in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqhIkZT_Y9Au"
      },
      "source": [
        "### Library of Helper Functions\n",
        "\n",
        "Below is a library of helpful functions. Most of these came from in class examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oj0wh2vUY9Av"
      },
      "outputs": [],
      "source": [
        "# Load required Python libraries.\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "## Check is element of array is NaN\n",
        "def check_nan(A):\n",
        "    return np.sum(np.isnan(A))\n",
        "\n",
        "## Calculate gradient with central finite difference\n",
        "def my_grad_approx(x,f,eps1,verbose=False):\n",
        "    '''\n",
        "    Calculate gradient of function my_f using central difference formula\n",
        "    \n",
        "    Inputs:\n",
        "        x - point for which to evaluate gradient\n",
        "        f - function to consider\n",
        "        eps1 - perturbation size\n",
        "        \n",
        "    Outputs:\n",
        "        grad - gradient (vector)\n",
        "    '''\n",
        "    \n",
        "    n = len(x)\n",
        "    grad = np.zeros(n)\n",
        "    \n",
        "    if(verbose):\n",
        "        print(\"***** my_grad_approx at x = \",x,\"*****\")\n",
        "    \n",
        "    for i in range(0,n):\n",
        "        \n",
        "        # Create vector of zeros except eps in position i\n",
        "        e = np.zeros(n)\n",
        "        e[i] = eps1\n",
        "        \n",
        "        # Finite difference formula\n",
        "        my_f_plus = f(x + e)\n",
        "        my_f_minus = f(x - e)\n",
        "        \n",
        "        # Diagnostics\n",
        "        if(verbose):\n",
        "            print(\"e[\",i,\"] = \",e)\n",
        "            print(\"f(x + e[\",i,\"]) = \",my_f_plus)\n",
        "            print(\"f(x - e[\",i,\"]) = \",my_f_minus)\n",
        "        \n",
        "        \n",
        "        grad[i] = (my_f_plus - my_f_minus)/(2*eps1)\n",
        "    \n",
        "    if(verbose):\n",
        "        print(\"***** Done. ***** \\n\")\n",
        "    \n",
        "    return grad\n",
        "\n",
        "## Calculate gradient using central finite difference and my_hes_approx\n",
        "def my_hes_approx(x,grad,eps2):\n",
        "    '''\n",
        "    Calculate Hessian of function my_f using central difference formula and my_grad\n",
        "    \n",
        "    Inputs:\n",
        "        x - point for which to evaluate gradient\n",
        "        grad - function to calculate the gradient\n",
        "        eps2 - perturbation size (for Hessian NOT gradient approximation)\n",
        "        \n",
        "    Outputs:\n",
        "        H - Hessian (matrix)\n",
        "    '''\n",
        "    \n",
        "    n = len(x)\n",
        "    H = np.zeros([n,n])\n",
        "    \n",
        "    for i in range(0,n):\n",
        "        # Create vector of zeros except eps in position i\n",
        "        e = np.zeros(n)\n",
        "        e[i] = eps2\n",
        "        \n",
        "        # Evaluate gradient twice\n",
        "        grad_plus = grad(x + e)\n",
        "        grad_minus = grad(x - e)\n",
        "        \n",
        "        # Notice we are building the Hessian by column (or row)\n",
        "        H[:,i] = (grad_plus - grad_minus)/(2*eps2)\n",
        "\n",
        "    return H\n",
        "\n",
        "## Linear algebra calculation\n",
        "def xxT(u):\n",
        "    '''\n",
        "    Calculates u*u.T to circumvent limitation with SciPy\n",
        "    \n",
        "    Arguments:\n",
        "    u - numpy 1D array\n",
        "    \n",
        "    Returns:\n",
        "    u*u.T\n",
        "    \n",
        "    Assume u is a nx1 vector.\n",
        "    Recall: NumPy does not distinguish between row or column vectors\n",
        "    \n",
        "    u.dot(u) returns a scalar. This functon returns an nxn matrix.\n",
        "    '''\n",
        "    \n",
        "    n = len(u)\n",
        "    A = np.zeros([n,n])\n",
        "    for i in range(0,n):\n",
        "        for j in range(0,n):\n",
        "            A[i,j] = u[i]*u[j]\n",
        "    \n",
        "    return A\n",
        "\n",
        "## Analyze Hessian\n",
        "def analyze_hes(B):\n",
        "    print(B,\"\\n\")\n",
        "    \n",
        "    l = linalg.eigvals(B)\n",
        "    print(\"Eigenvalues: \",l,\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXr-rYxbY9Ax"
      },
      "source": [
        "### Main Function\n",
        "\n",
        "Below is the main function. You need to complete details in four functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Pvpre7a0Y9Ax"
      },
      "outputs": [],
      "source": [
        "def unconstrained_newton(calc_f,calc_grad,calc_hes,x0,verbose=False,max_iter=50,\n",
        "                         algorithm=\"newton\",globalization=\"line-search\", # specify algorithm\n",
        "                         eps_dx=1E-6,eps_df=1E-6, # Convergence tolerances (all)\n",
        "                         eta_ls=0.25,rho_ls=0.9,alpha_max=1.0, # line search parameters\n",
        "                         delta_max_tr=10.0,delta_0_tr=2.0, # trust region parameters\n",
        "                         kappa_1_tr = 0.25, kappa_2_tr = 0.75, gamma_tr=0.125 # trust region parameters\n",
        "                        ):\n",
        "    '''\n",
        "    Newton-Type Methods for Unconstrained Nonlinear Continuous Optimization\n",
        "    \n",
        "    Arguments (required):\n",
        "        calc_f : function f(x) to minimize [scalar]\n",
        "        calc_grad: gradient of f(x) [vector]\n",
        "        calc_hes: Hessian of f(x) [matrix]\n",
        "    \n",
        "    Arguments (options):\n",
        "        algorithm : specify main algorithm.\n",
        "            choices: \"newton\", \"sr1\", \"bfgs\", \"steepest-descent\"\n",
        "        \n",
        "        globalization : specify globalization strategy\n",
        "            choices: \"none\", \"line-search\", \"trust-region\"\n",
        "       \n",
        "        eps_dx : tolerance for step size norm (convergence), eps1 in notes\n",
        "        \n",
        "        eps_df : tolerance for gradient norm (convergence), eps2 in notes\n",
        "        \n",
        "        eta_ls : parameter for Goldstein-Armijo conditions (line search only)\n",
        "        \n",
        "        rho_ls : parameter to shrink (backstep) line search\n",
        "        \n",
        "        alpha_max : initial step length scaling for line search and/or steepest-descent\n",
        "    \n",
        "        delta_max_tr : maximum trust region size\n",
        "        \n",
        "        delta_0_tr : initial trust region size\n",
        "        \n",
        "        kappa_1_tr : 'shrink' tolerance for trust region\n",
        "        \n",
        "        kappa_2_tr : 'expand' tolerance for trust region\n",
        "        \n",
        "        gamma_tr : 'accept step' tolerance for trust region\n",
        "    \n",
        "    Returns:\n",
        "        x : iteration history for x (decision variables) [list of numpy arrays]\n",
        "        f : iteration history for f(x) (objective values) [list of numpy arrays]\n",
        "        p : iteration history for p (steps)\n",
        "        B : iteration history for Hessian approximations [list of numpy arrays]\n",
        "    '''\n",
        "    \n",
        "    # Allocate outputs as empty lists\n",
        "    x = [] # decision variables\n",
        "    f = [] # objective values\n",
        "    p = [] # steps\n",
        "    grad = [] # gradients\n",
        "    alpha = [] # line search / steepest descent step scalar\n",
        "    B = [] # Hessian approximation\n",
        "    delta = [] # trust region size\n",
        "    rho = [] # trust region actual/prediction ratio\n",
        "    step_accepted = [] # step status for trust region. True means accepted. False means rejected.\n",
        "    \n",
        "    # Note: alpha, delta and rho will remain empty lists unless used in the algorithm below\n",
        "    \n",
        "    # Store starting point\n",
        "    x.append(x0)\n",
        "    k = 0\n",
        "    \n",
        "    flag = True\n",
        "    \n",
        "    # Print header for iteration information\n",
        "    print(\"Iter. \\tf(x) \\t\\t||grad(x)|| \\t||p|| \\t\\tmin(eig(B)) \\talpha \\t\\tdelta \\t\\tstep\")\n",
        "    \n",
        "    while flag and k < max_iter:\n",
        "        # Evaluate f(x) at current iteration\n",
        "        f.append(calc_f(x[k]))\n",
        "        \n",
        "        # Evaluate gradient\n",
        "        grad.append(calc_grad(x[k]))\n",
        "        \n",
        "        if(check_nan(grad[k])):\n",
        "            print(\"WARNING: gradiant calculation returned NaN\")\n",
        "            break\n",
        "        \n",
        "        if verbose:\n",
        "            print(\"\\n\")\n",
        "            print(\"k = \",k)\n",
        "            print(\"x = \",x[k])\n",
        "            print(\"grad = \",grad[k])\n",
        "            print(\"f = \",f[k])\n",
        "\n",
        "        # Calculate exact Hessian or update approximation\n",
        "        if(algorithm == \"newton\"):\n",
        "            B.append(calc_hes(x[k]))\n",
        "        \n",
        "        elif k == 0 or algorithm == \"steepest-descent\":\n",
        "            # Initialize or set to identity\n",
        "            B.append(np.eye(len(x0)))\n",
        "        \n",
        "        elif algorithm == \"sr1\" or algorithm == \"bfgs\":\n",
        "            # Change in x\n",
        "            s = x[k] - x[k-1]\n",
        "\n",
        "            # Change in gradient\n",
        "            y = grad[k] - grad[k-1]\n",
        "\n",
        "            if verbose:\n",
        "                print(\"s = \",s)\n",
        "                print(\"y = \",y)\n",
        "            \n",
        "            if algorithm == \"sr1\": # Calculate SR1 update\n",
        "                dB = sr1_update(s, y, k, B, verbose)\n",
        "                B.append(B[k-1] + dB)\n",
        "                \n",
        "            else: # Calculate BFGS update  \n",
        "                dB = bfgs_update(s, y, k, B, verbose)\n",
        "                B.append(B[k-1] + dB) \n",
        "\n",
        "        else:\n",
        "            print(\"WARNING. algorithm = \",algorithm,\" is not supported.\")\n",
        "            break\n",
        "\n",
        "        if verbose:\n",
        "            print(\"B = \\n\",B[k])\n",
        "            print(\"B[k].shape = \",B[k].shape)\n",
        "            \n",
        "        if(check_nan(B[k])):\n",
        "            print(\"WARNING: Hessian update returned NaN\")\n",
        "            break\n",
        "            \n",
        "        c = np.linalg.cond(B[k])\n",
        "        if c > 1E12:\n",
        "            flag = False\n",
        "            print(\"Warning: Hessian approximation is near singular.\")\n",
        "            print(\"B[k] = \\n\",B[k])\n",
        "        \n",
        "        else:\n",
        "            \n",
        "            # Solve linear system to calculate step\n",
        "            pk = linalg.solve(B[k],-grad[k])\n",
        "            \n",
        "            if globalization == \"none\":\n",
        "                if algorithm == \"steepest-descent\":\n",
        "                    # Save step and scale by alpha_max\n",
        "                    p.append(pk*alpha_max)\n",
        "                    \n",
        "                else:\n",
        "                    # Take full step\n",
        "                    p.append(pk)\n",
        "                    \n",
        "                # Apply step and calculate x[k+1]\n",
        "                x.append(x[k] + p[k])\n",
        "                    \n",
        "            elif globalization == \"line-search\":\n",
        "                \n",
        "                # Line Search Function\n",
        "                update, alphak = line_search(x, f, grad, calc_f, pk, k, alpha_max, eta_ls, rho_ls, verbose)\n",
        "                \n",
        "                # Now the line search is complete, apply final value of alphak\n",
        "                p.append(update)\n",
        "                \n",
        "                # Save alpha\n",
        "                alpha.append(alphak)\n",
        "                \n",
        "                # Apply step and calculate x[k+1]\n",
        "                x.append(x[k] + p[k])\n",
        "            \n",
        "            elif globalization == \"trust-region\":\n",
        "                \n",
        "                # Trust region function\n",
        "                update = trust_region(x, grad, B, delta, k, pk, delta_0_tr, verbose)\n",
        "                p.append(update)\n",
        "                \n",
        "                ### Trust region management\n",
        "\n",
        "                # Actual reduction\n",
        "                ared = f[k] - calc_f(x[k] + p[k])\n",
        "\n",
        "                # Predicted reduction\n",
        "                pred = -(grad[k].dot(p[k]) + 0.5*p[k].dot(B[k].dot(p[k])))\n",
        "\n",
        "                # Calculate rho\n",
        "                if ared == 0 and pred == 0:\n",
        "                    # This occurs is the gradient is zero and Hessian is P.D.\n",
        "                    rho.append(1E4)\n",
        "                else:\n",
        "                    rho.append(ared/pred)\n",
        "\n",
        "                if(verbose):\n",
        "                    print(\"f[k] = \",f[k])\n",
        "                    print(\"p[k] = \",p[k])\n",
        "                    print(\"f(x[k] + p[k]) = \",calc_f(x[k] + p[k]))\n",
        "                    print(\"ared = \",ared)\n",
        "                    print(\"pred = \",pred)\n",
        "                    print(\"rho = \",rho[k])\n",
        "\n",
        "                ## Check trust region shrink/expand logic\n",
        "                if rho[k] < kappa_1_tr:\n",
        "                    # Shrink trust region\n",
        "                    delta.append(kappa_1_tr*linalg.norm(p[k]))\n",
        "\n",
        "                elif rho[k] > kappa_2_tr and np.abs(linalg.norm(p[k]) - delta[k]) < 1E-6:\n",
        "                    # Expand trust region\n",
        "                    delta.append(np.min([2*delta[k], delta_max_tr]))\n",
        "\n",
        "                else:\n",
        "                    # Keep trust region same size\n",
        "                    delta.append(delta[k])\n",
        "\n",
        "                # Compute step\n",
        "                if rho[k] > gamma_tr:\n",
        "                    # Take step\n",
        "                    x.append(x[k] + p[k])\n",
        "                    step_accepted.append(True)\n",
        "                else:\n",
        "                    # Skip step\n",
        "                    x.append(x[k])\n",
        "                    step_accepted.append(False)\n",
        "            else:\n",
        "                print(\"Warning: globalization strategy not supported\")\n",
        "\n",
        "            if verbose:\n",
        "                print(\"p = \",p[k])\n",
        "\n",
        "            # Calculate norms\n",
        "            norm_p = linalg.norm(p[k])\n",
        "            norm_g = linalg.norm(grad[k])\n",
        "\n",
        "            # Calculate eigenvalues of Hessian (for display only)\n",
        "            min_ev = np.min(np.real(linalg.eigvals(B[k])))\n",
        "\n",
        "            '''\n",
        "            print(\"f[k] = \",f[k])\n",
        "            print(\"norm_g = \",norm_g)\n",
        "            print(\"norm_g = \",norm_p)\n",
        "            print(\"min_ev = \",min_ev)\n",
        "            '''\n",
        "            \n",
        "            print(k,'  \\t{0: 1.4e} \\t{1:1.4e} \\t{2:1.4e} \\t{3: 1.4e}'.format(f[k],norm_g,norm_p,min_ev),end='')\n",
        "\n",
        "            # Python tip. The expression 'if my_list' is false if 'my_list' is empty\n",
        "            if not alpha:\n",
        "                # alpha is an empty list\n",
        "                print(' \\t -------',end='')\n",
        "            else:\n",
        "                # otherwise print value of alpha\n",
        "                print(' \\t{0: 1.2e}'.format(alpha[k]),end='')\n",
        "            \n",
        "            if not delta:\n",
        "                # delta is an empty list\n",
        "                print(' \\t -------',end='')\n",
        "            else:\n",
        "                # otherwise print value of alpha\n",
        "                print(' \\t{0: 1.2e}'.format(delta[k]),end='')\n",
        "                \n",
        "            if not step_accepted:\n",
        "                print(' \\t -----')\n",
        "            else:\n",
        "                if step_accepted[k]:\n",
        "                    print(' \\t accept')\n",
        "                else:\n",
        "                    print(' \\t reject')\n",
        "            \n",
        "            # Check convergence criteria.\n",
        "            flag = (norm_p > eps_dx) and (norm_g > eps_df)\n",
        "\n",
        "            # Update iteration counter\n",
        "            k = k + 1\n",
        "    \n",
        "    if(k == max_iter and flag):\n",
        "        print(\"Reached maximum number of iterations.\")\n",
        "    \n",
        "    print(\"x* = \",x[-1])\n",
        "    \n",
        "    return x,f,p,B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tAGtAv2eY9Az"
      },
      "outputs": [],
      "source": [
        "def sr1_update(s, y, k, B, verbose):\n",
        "    \"\"\" \n",
        "    Function that implements the sr1 optimization algorithm\n",
        "    \n",
        "    Inputs:\n",
        "    s : Change in x\n",
        "    y : Change in gradient\n",
        "    k : Iteration number\n",
        "    B : Hessian approximation\n",
        "    verbose : toggles verbose output (True or False)\n",
        "    \n",
        "    Outputs:\n",
        "    dB : Update to Hessian approximation\n",
        "    \"\"\"\n",
        "    \n",
        "    # SR1 formulation\n",
        "    u = y - B[k-1].dot(s)\n",
        "    denom = (u).dot(s)\n",
        "\n",
        "    # Formula: dB = u * u.T / (u.T * s) if u is a column vector.\n",
        "    if abs(denom) <= 1E-10:\n",
        "        # Skip update\n",
        "        dB = 0\n",
        "    else:\n",
        "        # Calculate update\n",
        "        dB = xxT(u)/denom \n",
        "\n",
        "    if(verbose):\n",
        "        print(\"SR1 update denominator, (y-B[k-1]*s).T*s = \",denom)\n",
        "        print(\"SR1 update u = \",u)\n",
        "        print(\"SR1 update u.T*u/(u.T*s) = \\n\",dB)\n",
        "    \n",
        "    return dB #return the update to the Hessian approximation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hwPbfN-DY9A0"
      },
      "outputs": [],
      "source": [
        "def bfgs_update(s, y, k, B, verbose):\n",
        "    \"\"\" \n",
        "    Function that implements the BFGS optimization algorithm\n",
        "    \n",
        "    Inputs:\n",
        "    s : Change in x\n",
        "    y : Change in gradient\n",
        "    k : Iteration number\n",
        "    B : Hessian approximation\n",
        "    verbose : toggles verbose output (True or False)\n",
        "    \n",
        "    Outputs:\n",
        "    dB : Update to Hessian approximation\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define constant used to check norm of the update\n",
        "    # See Eq. (3.19) in Biegler (2010)\n",
        "    C2 = 1E-4\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Calculate intermediate\n",
        "    sy = s.dot(y)\n",
        "    \n",
        "    # Calculate Term 2 denominator\n",
        "    # s.T * Bk * s\n",
        "    d2 = s.dot(B[k-1].dot(s))\n",
        "    \n",
        "    # Condition check\n",
        "    C2norm = C2*linalg.norm(s,2)**2\n",
        "    if sy <= C2norm or d2 <= 1E-8:\n",
        "        skip = True\n",
        "    else:\n",
        "        skip = False   \n",
        "    # Add your solution here\n",
        "    dB = -1*xxT(B[k-1].dot(s))/d2 + xxT(y)/sy\n",
        "        \n",
        "    return dB #return the update to the Hessian approximation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "goBlGhsiY9A0"
      },
      "outputs": [],
      "source": [
        "def line_search(x, f, grad, calc_f, pk, k, alpha_max, eta_ls, rho_ls, verbose):\n",
        "    \"\"\"\n",
        "    Function that implements the line search globalization strategy\n",
        "    \n",
        "    Inputs:\n",
        "    x : decision variables\n",
        "    f : objective values\n",
        "    grad : gradients\n",
        "    calc_f : function f(x) to minimize [scalar]\n",
        "    pk : step\n",
        "    k - Iteration number\n",
        "    alpha_max : initial step length scaling for line search and/or steepest-descent\n",
        "    eta_ls : parameter for Goldstein-Armijo conditions (line search only)\n",
        "    rho_ls : parameter to shrink (backstep) line search\n",
        "    verbose : toggles verbose output (True or False)\n",
        "    \n",
        "    Outputs:\n",
        "    update : update to p\n",
        "    alphak : update to alpha\n",
        "    \"\"\"\n",
        "    \n",
        "    # Flag - continue line search?\n",
        "    ls = True\n",
        "\n",
        "    ## Initialize alpha\n",
        "    alphak = alpha_max\n",
        "\n",
        "    if(verbose):\n",
        "        print(\"\\t LINE SEARCH\")\n",
        "\n",
        "    i = 1\n",
        "    while ls:\n",
        "\n",
        "        # Calculate test point (if step accepted)\n",
        "        xtest = x[k] + alphak*pk\n",
        "\n",
        "        # Evaluate f(x) at test point. This is used for Armijo and Goldstein conditions\n",
        "        ftest = calc_f(xtest)\n",
        "        # Add your solution here\n",
        "        # Armijo-Goldstein conditions \n",
        "        # Armijo\n",
        "        arm = ftest + eta_ls*alphak*np.matmul(grad[k].T, pk)\n",
        "        # Goldstein\n",
        "        gold = ftest + (1-eta_ls)*alphak*np.matmul(grad[k].T,pk)\n",
        "        if ftest < gold:\n",
        "            ls = False\n",
        "            print(\"The algorithm failed as the Goldstein criteria does not meet!\")\n",
        "        \n",
        "        # Armijo condition\n",
        "        if ftest < arm:\n",
        "            ls = False\n",
        "            print(\"The algorithm failed as the Armijo criteria does not meet!\")\n",
        "\n",
        "        # Stopping Criteria\n",
        "        if ftest <= calc_f(x[k]) + eta_ls*alphak*np.matmul(grad[k].T, pk):\n",
        "          ls = False\n",
        "        alphak = alphak * rho_ls\n",
        "\n",
        "    # Now the line search is complete, apply final value of alphak\n",
        "    update = alphak*pk\n",
        "    \n",
        "    return update, alphak\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mi6c2jmTY9A1"
      },
      "outputs": [],
      "source": [
        "def trust_region(x, grad, B, delta, k, pk, delta_0_tr, verbose):\n",
        "    \"\"\" \n",
        "    Function that implements the trust region globalization strategy\n",
        "    \n",
        "    Inputs:\n",
        "    x : decision variables\n",
        "    grad : gradients\n",
        "    B : Hessian approximation\n",
        "    delta : trust region size\n",
        "    k : Iteration number\n",
        "    pk : step\n",
        "    delta_0_tr : initial trust region size\n",
        "    verbose : toggles verbose output (True or False)\n",
        "    \n",
        "    Outputs:\n",
        "    update : update to p\n",
        "    \"\"\"\n",
        "    \n",
        "    ### Initialize trust region radius\n",
        "    if(k == 0):\n",
        "        delta.append(delta_0_tr)\n",
        "\n",
        "    grad_zero = (linalg.norm(grad[k]) < 1E-14)\n",
        "\n",
        "    ### Powell dogleg step\n",
        "\n",
        "    # Calculate Cauchy step (pC)\n",
        "    denom = grad[k].dot(B[k].dot(grad[k]))\n",
        "    if verbose:\n",
        "        print(\"TR: Cauchy step. grad.T*B*grad = \",denom)\n",
        "    if denom > 0:\n",
        "        # Term in ( ) is a scalar\n",
        "        pC = -(grad[k].dot(grad[k])/denom)*grad[k]\n",
        "    elif grad_zero:\n",
        "        pC = np.zeros(len(x[k]))\n",
        "    else:\n",
        "        pC = - delta[k]/linalg.norm(grad[k])*grad[k]\n",
        "\n",
        "    # Use Newton step (calculate above)\n",
        "    pN = pk\n",
        "    dot_pC = np.dot(pC, pC)\n",
        "    norm_pC = np.sqrt(dot_pC)\n",
        "    # Determine step\n",
        "    if linalg.norm(pN) <= delta[k]:\n",
        "        # Take Newton step. pN is inside the trust region.\n",
        "        update = pN\n",
        "        \n",
        "    # Add your solution here\n",
        "    # If the Cauchy point is outside the trust region,\n",
        "    # then return the point where the path intersects the boundary.\n",
        "    elif norm_pC >= delta[k]:\n",
        "        update = delta[k] * pC / norm_pC\n",
        "\n",
        "    else:\n",
        "      pN_pC = pN - pC\n",
        "      dot_pN_pC = np.dot(pN_pC, pN_pC)\n",
        "      dot_pC_pN_pC = np.dot(pC, pN_pC)\n",
        "      fact = dot_pC_pN_pC ** 2 - dot_pN_pC * (dot_pC - delta[k] ** 2)\n",
        "      tau = (-dot_pC_pN_pC + np.sqrt(fact)) / dot_pN_pC\n",
        "      update = pC + tau * pN_pC\n",
        "    return update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ab9IYz4Y9A1"
      },
      "source": [
        "### Feature Status\n",
        "\n",
        "For each feature, please indicate the status upon submission.\n",
        "\n",
        "#### SR1\n",
        "\n",
        "*Status*: Implemented and tested\n",
        "\n",
        "*Details:* The python code provided by the Notebook, I only used it to perform required algorithms, figuring out the relationship to the unconstrained optimization function, and use its structure for the BFGS implementation.\n",
        "\n",
        "#### BFGS\n",
        "\n",
        "*Status*: Implemented and tested\n",
        "\n",
        "*Details:* In my opinion, this function was easy to implement as we have the structure of the SR1. The only things that I change were each particle formula and the final formula of the dB.\n",
        "\n",
        "#### Line Search\n",
        "\n",
        "*Status*: Implemented and tested\n",
        "\n",
        "*Details:* In this function, my first challenge was applying the gradient where I did not include its id based on the iterations. The Armijo and Goldstein conditions were based on our previous Notebook with minor modification. The other problem that I faced was not defining the stopping criteria. All in all, the function works but with more steps rather than the ones provided in the main Notebook. \n",
        "\n",
        "#### Trust Region\n",
        "\n",
        "*Status*: Implemented and tested\n",
        "\n",
        "*Details:* For this part, I use the traditional approach of Trust Region method without Cholesky factorization. In order to implement the algorithm, I used the formula provided by Bigler book. I had some minor challenges in implementing the boundary state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7m7wJj8Y9A1"
      },
      "source": [
        "## Benchmark Tests\n",
        "\n",
        "In the remainder of the assignment, we will compare using several variants of Newton-type methods in different test problems taken from in class examples. For each problem at a given starting point, we will consider ten algorithm cases:\n",
        "1. Newton method with **exact Hessian** and no globalization strategy\n",
        "2. Newton method with exact Hessian and line search\n",
        "3. Newton method with exact Hessian and Powell dogleg trust region\n",
        "4. Quasi-Newton method with **SR1 Hessian approximation** and no globalization strategy\n",
        "5. Quasi-Newton method with SR1 Hessian approximation and line search\n",
        "6. Quasi-Newton method with SR1 Hessian approximation and Powell dogleg trust region\n",
        "7. Quasi-Newton method with **BFGS Hessian approximation** and no globalization strategy\n",
        "8. Quasi-Newton method with BFGS Hessian approximation and line search\n",
        "9. Quasi-Newton method with BFGS Hessian approximation and Powell dogleg trust region\n",
        "10. **Steepest descent** with line search\n",
        "\n",
        "We will then assess each candidate solution by the eigenvalues of the true Hessian. The norm of the gradient is already displayed.\n",
        "\n",
        "All of this analysis has been automated in a function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "d3MG-F39Y9A2"
      },
      "outputs": [],
      "source": [
        "def check_sln(x,calc_hes):\n",
        "    Hval = calc_hes(x)\n",
        "    l, v = linalg.eig(Hval)\n",
        "    print(\"Eigenvalues of Hessian at x* = \",l)\n",
        "\n",
        "def benchmark(x0,calc_f,calc_grad,calc_hes,verbose,cases=range(0,10)):\n",
        "    '''\n",
        "    Test 10 algorithm cases for a single starting point\n",
        "    \n",
        "    Arguments:\n",
        "        x0 - starting point\n",
        "        calc_f - function to evaluate objective\n",
        "        calc_grad - function to evaluate gradient\n",
        "        calc_hes - function to evaluate Hessian\n",
        "        verbose - toggles verbose output (True or False)\n",
        "        cases - list of cases to consider. Especially helpful for debugging.\n",
        "            For example, setting cases=[1, 2] runs only case 2 and 3 (recall, Python starting counting at 0)\n",
        "    '''\n",
        "    \n",
        "    for i in cases:\n",
        "        if i == 0:\n",
        "            print(\"***Case 1: Newton method with exact Hessian and no globalization strategy***\")\n",
        "            x1,f,p,B = unconstrained_newton(calc_f,calc_grad,calc_hes,x0,verbose,\n",
        "                                            algorithm=\"newton\",globalization=\"none\")\n",
        "            check_sln(x1[-1],calc_hes)\n",
        "            print(\"\\n\")\n",
        "    \n",
        "        if i == 1:\n",
        "            print(\"***Case 2: Newton method with exact Hessian and line search***\")\n",
        "            x2,f,p,B = unconstrained_newton(calc_f,calc_grad,calc_hes,x0,verbose,\n",
        "                                            algorithm=\"newton\",globalization=\"line-search\")\n",
        "            check_sln(x2[-1],calc_hes)\n",
        "            print(\"\\n\")\n",
        "            \n",
        "        if i == 2:\n",
        "            print(\"***Case 3: Newton method with exact Hessian and trust region***\")\n",
        "            x3,f,p,B = unconstrained_newton(calc_f,calc_grad,calc_hes,x0,verbose,\n",
        "                                            algorithm=\"newton\",globalization=\"trust-region\")\n",
        "            check_sln(x3[-1],calc_hes)\n",
        "            print(\"\\n\")\n",
        "            \n",
        "        if i == 3:\n",
        "            print(\"***Case 4: Quasi-Newton method with SR1 Hessian approximation and no globalization strategy***\")\n",
        "            x4,f,p,B = unconstrained_newton(calc_f,calc_grad,calc_hes,x0,verbose,\n",
        "                                            algorithm=\"sr1\",globalization=\"none\")\n",
        "            check_sln(x4[-1],calc_hes)\n",
        "            print(\"\\n\")\n",
        "            \n",
        "        if i == 4:\n",
        "            print(\"***Case 5: Quasi-Newton method with SR1 Hessian approximation and line search***\")\n",
        "            x5,f,p,B = unconstrained_newton(calc_f,calc_grad,calc_hes,x0,verbose,\n",
        "                                            algorithm=\"sr1\",globalization=\"line-search\")\n",
        "            check_sln(x5[-1],calc_hes)\n",
        "            print(\"\\n\")\n",
        "            \n",
        "        if i == 5:\n",
        "            print(\"***Case 6: Quasi-Newton method with SR1 Hessian approximation and trust region***\")\n",
        "            x6,f,p,B = unconstrained_newton(calc_f,calc_grad,calc_hes,x0,verbose,\n",
        "                                            algorithm=\"sr1\",globalization=\"trust-region\")\n",
        "            check_sln(x6[-1],calc_hes)\n",
        "            print(\"\\n\")\n",
        "\n",
        "        if i == 6:\n",
        "            print(\"***Case 7: Quasi-Newton method with BFGS Hessian approximation and no globalization strategy***\")\n",
        "            x7,f,p,B = unconstrained_newton(calc_f,calc_grad,calc_hes,x0,verbose,\n",
        "                                            algorithm=\"bfgs\",globalization=\"none\")\n",
        "            check_sln(x7[-1],calc_hes)\n",
        "            print(\"\\n\")\n",
        "            \n",
        "        if i == 7:\n",
        "            print(\"***Case 8: Quasi-Newton method with BFGS Hessian approximation and line search***\")\n",
        "            x8,f,p,B = unconstrained_newton(calc_f,calc_grad,calc_hes,x0,verbose,\n",
        "                                            algorithm=\"bfgs\",globalization=\"line-search\")\n",
        "            check_sln(x8[-1],calc_hes)\n",
        "            print(\"\\n\")\n",
        "\n",
        "        if i == 8:\n",
        "            print(\"***Case 9: Quasi-Newton method with BFGS Hessian approximation and trust region***\")\n",
        "            x9,f,p,B = unconstrained_newton(calc_f,calc_grad,calc_hes,x0,verbose,\n",
        "                                            algorithm=\"bfgs\",globalization=\"trust-region\")\n",
        "            check_sln(x9[-1],calc_hes)\n",
        "            print(\"\\n\")\n",
        "\n",
        "        if i == 9:\n",
        "            print(\"***Case 10: Steepest Descent and line search***\")\n",
        "            x10,f,p,B = unconstrained_newton(calc_f,calc_grad,calc_hes,x0,verbose,\n",
        "                                             algorithm=\"steepest-descent\",globalization=\"line-search\")\n",
        "            check_sln(x10[-1],calc_hes)\n",
        "            print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs4QnhkYY9A2"
      },
      "source": [
        "### Quadratic Test Problem\n",
        "\n",
        "Start debugging your function with the following problem:\n",
        "\n",
        "$$\\min_x ~~ x_1^2 + (x_2 -1)^2$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xt0sXuTjY9A3"
      },
      "outputs": [],
      "source": [
        "def my_f(x):\n",
        "    return x[0]**2 + (x[1]-1)**2\n",
        "\n",
        "def my_grad(x):\n",
        "    return np.array([2*x[0], 2*(x[1] - 1) ])\n",
        "\n",
        "def my_hes(x):\n",
        "    return 2*np.eye(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEYjhjrkY9A3"
      },
      "source": [
        "#### Benchmark Cases\n",
        "\n",
        "The following code below runs cases 1 through 10. You can specify only a subset using the ``cases`` keyword."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8LLrfwItY9A3",
        "outputId": "98a0a9a3-3b9f-4770-cf42-a5c759d5b673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Case 1: Newton method with exact Hessian and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.0000e+01 \t6.3246e+00 \t3.1623e+00 \t 2.0000e+00 \t ------- \t ------- \t -----\n",
            "1   \t 0.0000e+00 \t0.0000e+00 \t0.0000e+00 \t 2.0000e+00 \t ------- \t ------- \t -----\n",
            "x* =  [0. 1.]\n",
            "Eigenvalues of Hessian at x* =  [2.+0.j 2.+0.j]\n",
            "\n",
            "\n",
            "***Case 2: Newton method with exact Hessian and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.0000e+01 \t6.3246e+00 \t2.8460e+00 \t 2.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "1   \t 1.0000e-01 \t6.3246e-01 \t2.8460e-01 \t 2.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "2   \t 1.0000e-03 \t6.3246e-02 \t2.8460e-02 \t 2.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t 1.0000e-05 \t6.3246e-03 \t2.8460e-03 \t 2.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t 1.0000e-07 \t6.3246e-04 \t2.8460e-04 \t 2.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t 1.0000e-09 \t6.3246e-05 \t2.8460e-05 \t 2.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t 1.0000e-11 \t6.3246e-06 \t2.8460e-06 \t 2.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "7   \t 1.0000e-13 \t6.3246e-07 \t2.8460e-07 \t 2.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [-3.00000000e-08  1.00000001e+00]\n",
            "Eigenvalues of Hessian at x* =  [2.+0.j 2.+0.j]\n",
            "\n",
            "\n",
            "***Case 3: Newton method with exact Hessian and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.0000e+01 \t6.3246e+00 \t2.0000e+00 \t 2.0000e+00 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t 1.3509e+00 \t2.3246e+00 \t1.1623e+00 \t 2.0000e+00 \t ------- \t 4.00e+00 \t accept\n",
            "2   \t 0.0000e+00 \t0.0000e+00 \t0.0000e+00 \t 2.0000e+00 \t ------- \t 4.00e+00 \t accept\n",
            "x* =  [0. 1.]\n",
            "Eigenvalues of Hessian at x* =  [2.+0.j 2.+0.j]\n",
            "\n",
            "\n",
            "***Case 4: Quasi-Newton method with SR1 Hessian approximation and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.0000e+01 \t6.3246e+00 \t6.3246e+00 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "1   \t 1.0000e+01 \t6.3246e+00 \t3.1623e+00 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "2   \t 1.9722e-31 \t8.8818e-16 \t5.0634e-16 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "x* =  [4.4408921e-17 1.0000000e+00]\n",
            "Eigenvalues of Hessian at x* =  [2.+0.j 2.+0.j]\n",
            "\n",
            "\n",
            "***Case 5: Quasi-Newton method with SR1 Hessian approximation and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.0000e+01 \t6.3246e+00 \t4.1495e+00 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "1   \t 9.7469e-01 \t1.9745e+00 \t8.8854e-01 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "2   \t 9.7469e-03 \t1.9745e-01 \t8.8854e-02 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t 9.7469e-05 \t1.9745e-02 \t8.8854e-03 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t 9.7469e-07 \t1.9745e-03 \t8.8854e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t 9.7469e-09 \t1.9745e-04 \t8.8854e-05 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t 9.7469e-11 \t1.9745e-05 \t8.8854e-06 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "7   \t 9.7469e-13 \t1.9745e-06 \t8.8854e-07 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [9.36600000e-08 9.99999969e-01]\n",
            "Eigenvalues of Hessian at x* =  [2.+0.j 2.+0.j]\n",
            "\n",
            "\n",
            "***Case 6: Quasi-Newton method with SR1 Hessian approximation and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.0000e+01 \t6.3246e+00 \t2.0000e+00 \t 1.0000e+00 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t 1.3509e+00 \t2.3246e+00 \t1.1623e+00 \t 1.0000e+00 \t ------- \t 4.00e+00 \t accept\n",
            "2   \t 4.9304e-32 \t4.4409e-16 \t4.2711e-16 \t 1.0000e+00 \t ------- \t 4.00e+00 \t reject\n",
            "x* =  [0. 1.]\n",
            "Eigenvalues of Hessian at x* =  [2.+0.j 2.+0.j]\n",
            "\n",
            "\n",
            "***Case 7: Quasi-Newton method with BFGS Hessian approximation and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.0000e+01 \t6.3246e+00 \t6.3246e+00 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "1   \t 1.0000e+01 \t6.3246e+00 \t3.1623e+00 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "2   \t 1.9722e-31 \t8.8818e-16 \t5.0634e-16 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "x* =  [4.4408921e-17 1.0000000e+00]\n",
            "Eigenvalues of Hessian at x* =  [2.+0.j 2.+0.j]\n",
            "\n",
            "\n",
            "***Case 8: Quasi-Newton method with BFGS Hessian approximation and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.0000e+01 \t6.3246e+00 \t4.1495e+00 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "1   \t 9.7469e-01 \t1.9745e+00 \t8.8854e-01 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "2   \t 9.7469e-03 \t1.9745e-01 \t8.8854e-02 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t 9.7469e-05 \t1.9745e-02 \t8.8854e-03 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t 9.7469e-07 \t1.9745e-03 \t8.8854e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t 9.7469e-09 \t1.9745e-04 \t8.8854e-05 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t 9.7469e-11 \t1.9745e-05 \t8.8854e-06 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "7   \t 9.7469e-13 \t1.9745e-06 \t8.8854e-07 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [9.36600000e-08 9.99999969e-01]\n",
            "Eigenvalues of Hessian at x* =  [2.+0.j 2.+0.j]\n",
            "\n",
            "\n",
            "***Case 9: Quasi-Newton method with BFGS Hessian approximation and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.0000e+01 \t6.3246e+00 \t2.0000e+00 \t 1.0000e+00 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t 1.3509e+00 \t2.3246e+00 \t1.1623e+00 \t 1.0000e+00 \t ------- \t 4.00e+00 \t accept\n",
            "2   \t 4.9304e-32 \t4.4409e-16 \t4.2711e-16 \t 1.0000e+00 \t ------- \t 4.00e+00 \t reject\n",
            "x* =  [0. 1.]\n",
            "Eigenvalues of Hessian at x* =  [2.+0.j 2.+0.j]\n",
            "\n",
            "\n",
            "***Case 10: Steepest Descent and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.0000e+01 \t6.3246e+00 \t4.1495e+00 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "1   \t 9.7469e-01 \t1.9745e+00 \t1.2955e+00 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "2   \t 9.5002e-02 \t6.1645e-01 \t4.0445e-01 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "3   \t 9.2597e-03 \t1.9245e-01 \t1.2627e-01 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "4   \t 9.0253e-04 \t6.0084e-02 \t3.9421e-02 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "5   \t 8.7969e-05 \t1.8758e-02 \t1.2307e-02 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "6   \t 8.5742e-06 \t5.8564e-03 \t3.8424e-03 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "7   \t 8.3572e-07 \t1.8284e-03 \t1.1996e-03 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "8   \t 8.1457e-08 \t5.7081e-04 \t3.7451e-04 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "9   \t 7.9395e-09 \t1.7821e-04 \t1.1692e-04 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "10   \t 7.7385e-10 \t5.5636e-05 \t3.6503e-05 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "11   \t 7.5426e-11 \t1.7370e-05 \t1.1396e-05 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "12   \t 7.3517e-12 \t5.4228e-06 \t3.5579e-06 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "13   \t 7.1656e-13 \t1.6930e-06 \t1.1108e-06 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "14   \t 6.9843e-14 \t5.2856e-07 \t3.4679e-07 \t 1.0000e+00 \t 6.56e-01 \t ------- \t -----\n",
            "x* =  [7.82734967e-08 9.99999974e-01]\n",
            "Eigenvalues of Hessian at x* =  [2.+0.j 2.+0.j]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "x0 = np.array([-3.0,2.0])\n",
        "benchmark(x0,my_f,my_grad,my_hes,False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxixgRP0Y9A4"
      },
      "source": [
        "#### Discussion and Analysis\n",
        "\n",
        "Classify the solutions.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "In all cases the eigen values are positive. Hence, the Hessian is positive define, which means that the function is strictly convex and the point is correspondent to the minimum.\n",
        "\n",
        "Should we expect the SR1, BFGS, and steepest descent (all with line search) to always have the same results for the first iteration? Explain in a few sentences.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "In the first iteration, the values are based on the initial values like $x_0$, $B_k$ which is the same for all these algorithms. So, only at the first iteration we expect the same result. \n",
        "\n",
        "For this problem, should we always expect all of the cases to converge to the same solution (regardless of starting point)? Explain in a few sentences.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "If the algorithms work perfectly without any divegence (which in this specific case, it happens), the algorithm should converge to the same results. The difference is in the number of steps that they need to achieve the optimal point (efficiency)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJznpFJCY9A4"
      },
      "source": [
        "### One-Dimensional Example\n",
        "\n",
        "Consider a scalar function $f(x): \\mathbb{R} \\rightarrow \\mathbb{R}$. Recall\n",
        "\n",
        "$$f(x) = 0.5 (x-1)^4 + (x+1)^3 - 10 x^2 + 5 x$$\n",
        "\n",
        "$$f'(x) = 6 - 8 x - 3 x^2 + 2 x^3$$\n",
        "\n",
        "$$f''(x) = -8 - 6 x + 6 x^2 $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fHynod1VY9A-"
      },
      "outputs": [],
      "source": [
        "## Define f(x)\n",
        "f_ = lambda x : 0.5*(x[0]-1)**4 + (x[0]+1)**3 - 10*x[0]**2 + 5*x[0]\n",
        "\n",
        "## Define f'(x)\n",
        "df_ = lambda x : (6 - 8*x[0] - 3*x[0]**2 + 2*x[0]**3)*np.ones(1)\n",
        "\n",
        "## Define f''(x)\n",
        "ddf_ = lambda x : (-8 - 6*x[0] + 6*x[0]**2)*np.ones((1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVWHADjHY9A-"
      },
      "source": [
        "#### Benchmark Cases with $x_0 = -3$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SG1D6QhbY9A-",
        "outputId": "ca71360d-3e86-40e8-f44d-f7087999b529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Case 1: Newton method with exact Hessian and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+01 \t5.1000e+01 \t7.9688e-01 \t 6.4000e+01 \t ------- \t ------- \t -----\n",
            "1   \t-8.6609e+00 \t1.2323e+01 \t3.5884e-01 \t 3.4341e+01 \t ------- \t ------- \t -----\n",
            "2   \t-1.1113e+01 \t1.9961e+00 \t8.5033e-02 \t 2.3474e+01 \t ------- \t ------- \t -----\n",
            "3   \t-1.1201e+01 \t1.0047e-01 \t4.7561e-03 \t 2.1125e+01 \t ------- \t ------- \t -----\n",
            "4   \t-1.1201e+01 \t3.0641e-04 \t1.4594e-05 \t 2.0996e+01 \t ------- \t ------- \t -----\n",
            "5   \t-1.1201e+01 \t2.8809e-09 \t1.3721e-10 \t 2.0996e+01 \t ------- \t ------- \t -----\n",
            "x* =  [-1.75447804]\n",
            "Eigenvalues of Hessian at x* =  [20.99602743+0.j]\n",
            "\n",
            "\n",
            "***Case 2: Newton method with exact Hessian and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+01 \t5.1000e+01 \t7.1719e-01 \t 6.4000e+01 \t 9.00e-01 \t ------- \t -----\n",
            "1   \t-7.5671e+00 \t1.5164e+01 \t3.6920e-01 \t 3.6964e+01 \t 9.00e-01 \t ------- \t -----\n",
            "2   \t-1.0917e+01 \t3.6917e+00 \t1.3054e-01 \t 2.5453e+01 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t-1.1193e+01 \t6.1148e-01 \t2.5274e-02 \t 2.1775e+01 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t-1.1201e+01 \t6.9866e-02 \t2.9821e-03 \t 2.1086e+01 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t-1.1201e+01 \t7.1070e-03 \t3.0451e-04 \t 2.1005e+01 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t-1.1201e+01 \t7.1196e-04 \t3.0517e-05 \t 2.0997e+01 \t 9.00e-01 \t ------- \t -----\n",
            "7   \t-1.1201e+01 \t7.1208e-05 \t3.0524e-06 \t 2.0996e+01 \t 9.00e-01 \t ------- \t -----\n",
            "8   \t-1.1201e+01 \t7.1210e-06 \t3.0524e-07 \t 2.0996e+01 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [-1.75447807]\n",
            "Eigenvalues of Hessian at x* =  [20.99602834+0.j]\n",
            "\n",
            "\n",
            "***Case 3: Newton method with exact Hessian and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+01 \t5.1000e+01 \t7.9688e-01 \t 6.4000e+01 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t-8.6609e+00 \t1.2323e+01 \t3.5884e-01 \t 3.4341e+01 \t ------- \t 2.00e+00 \t accept\n",
            "2   \t-1.1113e+01 \t1.9961e+00 \t8.5033e-02 \t 2.3474e+01 \t ------- \t 2.00e+00 \t accept\n",
            "3   \t-1.1201e+01 \t1.0047e-01 \t4.7561e-03 \t 2.1125e+01 \t ------- \t 2.00e+00 \t accept\n",
            "4   \t-1.1201e+01 \t3.0641e-04 \t1.4594e-05 \t 2.0996e+01 \t ------- \t 2.00e+00 \t accept\n",
            "5   \t-1.1201e+01 \t2.8809e-09 \t1.3721e-10 \t 2.0996e+01 \t ------- \t 2.00e+00 \t accept\n",
            "x* =  [-1.75447804]\n",
            "Eigenvalues of Hessian at x* =  [20.99602743+0.j]\n",
            "\n",
            "\n",
            "***Case 4: Quasi-Newton method with SR1 Hessian approximation and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+01 \t5.1000e+01 \t5.1000e+01 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "1   \t 2.5347e+06 \t2.1389e+05 \t5.0988e+01 \t 4.1950e+03 \t ------- \t ------- \t -----\n",
            "2   \t 1.4385e+01 \t5.0225e+01 \t1.1970e-02 \t 4.1960e+03 \t ------- \t ------- \t -----\n",
            "3   \t 1.3788e+01 \t4.9468e+01 \t7.8223e-01 \t 6.3240e+01 \t ------- \t ------- \t -----\n",
            "4   \t-8.7761e+00 \t1.1999e+01 \t2.5050e-01 \t 4.7900e+01 \t ------- \t ------- \t -----\n",
            "5   \t-1.0797e+01 \t4.4562e+00 \t1.4799e-01 \t 3.0111e+01 \t ------- \t ------- \t -----\n",
            "6   \t-1.1184e+01 \t8.7657e-01 \t3.6239e-02 \t 2.4188e+01 \t ------- \t ------- \t -----\n",
            "7   \t-1.1201e+01 \t9.3432e-02 \t4.3236e-03 \t 2.1610e+01 \t ------- \t ------- \t -----\n",
            "8   \t-1.1201e+01 \t2.3882e-03 \t1.1341e-04 \t 2.1058e+01 \t ------- \t ------- \t -----\n",
            "9   \t-1.1201e+01 \t6.8113e-06 \t3.2439e-07 \t 2.0998e+01 \t ------- \t ------- \t -----\n",
            "x* =  [-1.75447804]\n",
            "Eigenvalues of Hessian at x* =  [20.99602743+0.j]\n",
            "\n",
            "\n",
            "***Case 5: Quasi-Newton method with SR1 Hessian approximation and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+01 \t5.1000e+01 \t1.5761e+00 \t 1.0000e+00 \t 3.09e-02 \t ------- \t -----\n",
            "1   \t-1.0211e+01 \t5.5343e+00 \t1.3886e-01 \t 3.5871e+01 \t 9.00e-01 \t ------- \t -----\n",
            "2   \t-1.0847e+01 \t3.5416e+00 \t2.2211e-01 \t 1.4351e+01 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t-1.1192e+01 \t6.5150e-01 \t3.1059e-02 \t 1.8878e+01 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t-1.1201e+01 \t1.3197e-02 \t5.5497e-04 \t 2.1401e+01 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t-1.1201e+01 \t1.5497e-03 \t6.6457e-05 \t 2.0987e+01 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t-1.1201e+01 \t1.5441e-04 \t6.6217e-06 \t 2.0987e+01 \t 9.00e-01 \t ------- \t -----\n",
            "7   \t-1.1201e+01 \t1.5379e-05 \t6.5950e-07 \t 2.0987e+01 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [-1.75447797]\n",
            "Eigenvalues of Hessian at x* =  [20.99602545+0.j]\n",
            "\n",
            "\n",
            "***Case 6: Quasi-Newton method with SR1 Hessian approximation and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+01 \t5.1000e+01 \t2.0000e+00 \t 1.0000e+00 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t-7.0000e+00 \t9.0000e+00 \t3.0000e-01 \t 3.0000e+01 \t ------- \t 5.00e-01 \t accept\n",
            "2   \t-9.4350e+00 \t6.9360e+00 \t5.0000e-01 \t 6.8800e+00 \t ------- \t 5.00e-01 \t accept\n",
            "3   \t-1.1179e+01 \t9.8400e-01 \t6.2121e-02 \t 1.5840e+01 \t ------- \t 5.00e-01 \t accept\n",
            "4   \t-1.1199e+01 \t3.4480e-01 \t1.6119e-02 \t 2.1390e+01 \t ------- \t 5.00e-01 \t accept\n",
            "5   \t-1.1201e+01 \t1.0073e-02 \t4.8506e-04 \t 2.0766e+01 \t ------- \t 5.00e-01 \t accept\n",
            "6   \t-1.1201e+01 \t1.0867e-04 \t5.1775e-06 \t 2.0990e+01 \t ------- \t 5.00e-01 \t accept\n",
            "7   \t-1.1201e+01 \t3.3607e-08 \t1.6011e-09 \t 2.0990e+01 \t ------- \t 5.00e-01 \t accept\n",
            "x* =  [-1.75447804]\n",
            "Eigenvalues of Hessian at x* =  [20.99602743+0.j]\n",
            "\n",
            "\n",
            "***Case 7: Quasi-Newton method with BFGS Hessian approximation and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+01 \t5.1000e+01 \t5.1000e+01 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "1   \t 2.5347e+06 \t2.1389e+05 \t5.0988e+01 \t 4.1950e+03 \t ------- \t ------- \t -----\n",
            "2   \t 1.4385e+01 \t5.0225e+01 \t1.1970e-02 \t 4.1960e+03 \t ------- \t ------- \t -----\n",
            "3   \t 1.3788e+01 \t4.9468e+01 \t7.8223e-01 \t 6.3240e+01 \t ------- \t ------- \t -----\n",
            "4   \t-8.7761e+00 \t1.1999e+01 \t2.5050e-01 \t 4.7900e+01 \t ------- \t ------- \t -----\n",
            "5   \t-1.0797e+01 \t4.4562e+00 \t1.4799e-01 \t 3.0111e+01 \t ------- \t ------- \t -----\n",
            "6   \t-1.1184e+01 \t8.7657e-01 \t3.6239e-02 \t 2.4188e+01 \t ------- \t ------- \t -----\n",
            "7   \t-1.1201e+01 \t9.3432e-02 \t4.3236e-03 \t 2.1610e+01 \t ------- \t ------- \t -----\n",
            "8   \t-1.1201e+01 \t2.3882e-03 \t1.1341e-04 \t 2.1058e+01 \t ------- \t ------- \t -----\n",
            "9   \t-1.1201e+01 \t6.8113e-06 \t3.2439e-07 \t 2.0998e+01 \t ------- \t ------- \t -----\n",
            "x* =  [-1.75447804]\n",
            "Eigenvalues of Hessian at x* =  [20.99602743+0.j]\n",
            "\n",
            "\n",
            "***Case 8: Quasi-Newton method with BFGS Hessian approximation and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+01 \t5.1000e+01 \t1.5761e+00 \t 1.0000e+00 \t 3.09e-02 \t ------- \t -----\n",
            "1   \t-1.0211e+01 \t5.5343e+00 \t1.3886e-01 \t 3.5871e+01 \t 9.00e-01 \t ------- \t -----\n",
            "2   \t-1.0847e+01 \t3.5416e+00 \t2.2211e-01 \t 1.4351e+01 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t-1.1192e+01 \t6.5150e-01 \t3.1059e-02 \t 1.8878e+01 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t-1.1201e+01 \t1.3197e-02 \t5.5497e-04 \t 2.1401e+01 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t-1.1201e+01 \t1.5497e-03 \t6.6457e-05 \t 2.0987e+01 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t-1.1201e+01 \t1.5441e-04 \t6.6190e-06 \t 2.0995e+01 \t 9.00e-01 \t ------- \t -----\n",
            "7   \t-1.1201e+01 \t1.5434e-05 \t6.6159e-07 \t 2.0996e+01 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [-1.75447797]\n",
            "Eigenvalues of Hessian at x* =  [20.99602544+0.j]\n",
            "\n",
            "\n",
            "***Case 9: Quasi-Newton method with BFGS Hessian approximation and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+01 \t5.1000e+01 \t2.0000e+00 \t 1.0000e+00 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t-7.0000e+00 \t9.0000e+00 \t3.0000e-01 \t 3.0000e+01 \t ------- \t 5.00e-01 \t accept\n",
            "2   \t-9.4350e+00 \t6.9360e+00 \t5.0000e-01 \t 6.8800e+00 \t ------- \t 5.00e-01 \t accept\n",
            "3   \t-1.1179e+01 \t9.8400e-01 \t6.2121e-02 \t 1.5840e+01 \t ------- \t 5.00e-01 \t accept\n",
            "4   \t-1.1199e+01 \t3.4480e-01 \t1.6119e-02 \t 2.1390e+01 \t ------- \t 5.00e-01 \t accept\n",
            "5   \t-1.1201e+01 \t1.0073e-02 \t4.8506e-04 \t 2.0766e+01 \t ------- \t 5.00e-01 \t accept\n",
            "6   \t-1.1201e+01 \t1.0867e-04 \t5.1775e-06 \t 2.0990e+01 \t ------- \t 5.00e-01 \t accept\n",
            "7   \t-1.1201e+01 \t3.3607e-08 \t1.6006e-09 \t 2.0996e+01 \t ------- \t 5.00e-01 \t accept\n",
            "x* =  [-1.75447804]\n",
            "Eigenvalues of Hessian at x* =  [20.99602743+0.j]\n",
            "\n",
            "\n",
            "***Case 10: Steepest Descent and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+01 \t5.1000e+01 \t1.5761e+00 \t 1.0000e+00 \t 3.09e-02 \t ------- \t -----\n",
            "1   \t-1.0211e+01 \t5.5343e+00 \t4.4145e-01 \t 1.0000e+00 \t 7.98e-02 \t ------- \t -----\n",
            "2   \t-1.1066e+01 \t2.4979e+00 \t1.4525e-01 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "3   \t-1.1189e+01 \t7.0510e-01 \t4.5557e-02 \t 1.0000e+00 \t 6.46e-02 \t ------- \t -----\n",
            "4   \t-1.1200e+01 \t2.3725e-01 \t1.3796e-02 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "5   \t-1.1201e+01 \t5.4028e-02 \t3.1417e-03 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "6   \t-1.1201e+01 \t1.1850e-02 \t6.8907e-04 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "7   \t-1.1201e+01 \t2.6219e-03 \t1.5246e-04 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "8   \t-1.1201e+01 \t5.7902e-04 \t3.3670e-05 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "9   \t-1.1201e+01 \t1.2792e-04 \t7.4386e-06 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "10   \t-1.1201e+01 \t2.8259e-05 \t1.6433e-06 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "11   \t-1.1201e+01 \t6.2429e-06 \t3.6302e-07 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "x* =  [-1.75447811]\n",
            "Eigenvalues of Hessian at x* =  [20.9960292+0.j]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "x0 = np.ones(1)*(-3.0)\n",
        "benchmark(x0,f_,df_,ddf_,False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRdp-TsEY9A-"
      },
      "source": [
        "#### Discussion\n",
        "\n",
        "Did all of the cases converge to the nearby solution?\n",
        "\n",
        "**Answer**\n",
        "\n",
        "Yes, all the algorithms converge to the same optimal point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxXeIHuuY9A-"
      },
      "source": [
        "### Benchmark Case with $x_0 = 0$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Kb0-MORtY9A_",
        "outputId": "d8ad2d6f-cf95-4853-b628-ac2aebbbb47a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Case 1: Newton method with exact Hessian and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+00 \t6.0000e+00 \t7.5000e-01 \t-8.0000e+00 \t ------- \t ------- \t -----\n",
            "1   \t 3.4863e+00 \t8.4375e-01 \t9.2466e-02 \t-9.1250e+00 \t ------- \t ------- \t -----\n",
            "2   \t 3.5250e+00 \t1.1244e-02 \t1.2024e-03 \t-9.3511e+00 \t ------- \t ------- \t -----\n",
            "3   \t 3.5250e+00 \t1.3700e-06 \t1.4654e-07 \t-9.3488e+00 \t ------- \t ------- \t -----\n",
            "x* =  [0.65873679]\n",
            "Eigenvalues of Hessian at x* =  [-9.34881579+0.j]\n",
            "\n",
            "\n",
            "***Case 2: Newton method with exact Hessian and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "0   \t 1.5000e+00 \t6.0000e+00 \t6.7500e-01 \t-8.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "1   \t 3.5238e+00 \t1.5178e-01 \t1.4663e-02 \t-9.3163e+00 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "2   \t 3.5250e+00 \t1.4959e-02 \t1.4405e-03 \t-9.3458e+00 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "3   \t 3.5250e+00 \t1.4939e-03 \t1.4382e-04 \t-9.3485e+00 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "4   \t 3.5250e+00 \t1.4937e-04 \t1.4380e-05 \t-9.3488e+00 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "5   \t 3.5250e+00 \t1.4937e-05 \t1.4379e-06 \t-9.3488e+00 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "6   \t 3.5250e+00 \t1.4937e-06 \t1.4379e-07 \t-9.3488e+00 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [0.65873681]\n",
            "Eigenvalues of Hessian at x* =  [-9.34881576+0.j]\n",
            "\n",
            "\n",
            "***Case 3: Newton method with exact Hessian and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+00 \t6.0000e+00 \t7.5000e-01 \t-8.0000e+00 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t 3.4863e+00 \t8.4375e-01 \t9.2466e-02 \t-9.1250e+00 \t ------- \t 2.00e+00 \t accept\n",
            "2   \t 3.5250e+00 \t1.1244e-02 \t1.2024e-03 \t-9.3511e+00 \t ------- \t 2.00e+00 \t accept\n",
            "3   \t 3.5250e+00 \t1.3700e-06 \t1.4654e-07 \t-9.3488e+00 \t ------- \t 2.00e+00 \t accept\n",
            "x* =  [0.65873679]\n",
            "Eigenvalues of Hessian at x* =  [-9.34881579+0.j]\n",
            "\n",
            "\n",
            "***Case 4: Quasi-Newton method with SR1 Hessian approximation and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+00 \t6.0000e+00 \t6.0000e+00 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "1   \t 6.8550e+02 \t4.8600e+02 \t5.9268e+00 \t 8.2000e+01 \t ------- \t ------- \t -----\n",
            "2   \t 1.0400e+00 \t6.5685e+00 \t7.9036e-02 \t 8.3108e+01 \t ------- \t ------- \t -----\n",
            "3   \t 4.9789e-01 \t7.1411e+00 \t9.8572e-01 \t-7.2446e+00 \t ------- \t ------- \t -----\n",
            "4   \t 3.3844e+00 \t1.5942e+00 \t1.7989e-01 \t-8.8618e+00 \t ------- \t ------- \t -----\n",
            "5   \t 3.5249e+00 \t4.7859e-02 \t5.2432e-03 \t-9.1279e+00 \t ------- \t ------- \t -----\n",
            "6   \t 3.5250e+00 \t1.1831e-03 \t1.2649e-04 \t-9.3535e+00 \t ------- \t ------- \t -----\n",
            "7   \t 3.5250e+00 \t6.0994e-07 \t6.5210e-08 \t-9.3535e+00 \t ------- \t ------- \t -----\n",
            "x* =  [0.65873679]\n",
            "Eigenvalues of Hessian at x* =  [-9.34881579+0.j]\n",
            "\n",
            "\n",
            "***Case 5: Quasi-Newton method with SR1 Hessian approximation and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+00 \t6.0000e+00 \t2.0921e+00 \t 1.0000e+00 \t 3.49e-01 \t ------- \t -----\n",
            "1   \t-9.8250e+00 \t8.7067e+00 \t4.3186e-01 \t 7.0297e+00 \t 3.49e-01 \t ------- \t -----\n",
            "2   \t-1.1112e+01 \t1.8607e+00 \t6.8435e-02 \t 2.4470e+01 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t-1.1194e+01 \t5.3331e-01 \t2.4747e-02 \t 1.9396e+01 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t-1.1201e+01 \t2.2697e-02 \t9.9002e-04 \t 2.0633e+01 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t-1.1201e+01 \t1.9264e-03 \t8.2640e-05 \t 2.0980e+01 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t-1.1201e+01 \t1.9144e-04 \t8.2125e-06 \t 2.0980e+01 \t 9.00e-01 \t ------- \t -----\n",
            "7   \t-1.1201e+01 \t1.9015e-05 \t8.1571e-07 \t 2.0980e+01 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [-1.75447795]\n",
            "Eigenvalues of Hessian at x* =  [20.99602499+0.j]\n",
            "\n",
            "\n",
            "***Case 6: Quasi-Newton method with SR1 Hessian approximation and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+00 \t6.0000e+00 \t2.0000e+00 \t 1.0000e+00 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t-1.0500e+01 \t6.0000e+00 \t1.0000e+00 \t 6.0000e+00 \t ------- \t 4.00e+00 \t reject\n",
            "2   \t-1.0500e+01 \t6.0000e+00 \t2.5000e-01 \t 6.0000e+00 \t ------- \t 2.50e-01 \t accept\n",
            "3   \t-1.1201e+01 \t9.3750e-02 \t3.8462e-03 \t 2.4375e+01 \t ------- \t 2.50e-01 \t accept\n",
            "4   \t-1.1201e+01 \t1.3262e-02 \t6.3371e-04 \t 2.0927e+01 \t ------- \t 2.50e-01 \t accept\n",
            "5   \t-1.1201e+01 \t3.8373e-05 \t1.8284e-06 \t 2.0988e+01 \t ------- \t 2.50e-01 \t accept\n",
            "6   \t-1.1201e+01 \t1.5627e-08 \t7.4456e-10 \t 2.0988e+01 \t ------- \t 2.50e-01 \t reject\n",
            "x* =  [-1.75447804]\n",
            "Eigenvalues of Hessian at x* =  [20.99602741+0.j]\n",
            "\n",
            "\n",
            "***Case 7: Quasi-Newton method with BFGS Hessian approximation and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+00 \t6.0000e+00 \t6.0000e+00 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "1   \t 6.8550e+02 \t4.8600e+02 \t5.9268e+00 \t 8.2000e+01 \t ------- \t ------- \t -----\n",
            "2   \t 1.0400e+00 \t6.5685e+00 \t7.9036e-02 \t 8.3108e+01 \t ------- \t ------- \t -----\n",
            "3   \t 4.9789e-01 \t7.1411e+00 \t9.8572e-01 \t-7.2446e+00 \t ------- \t ------- \t -----\n",
            "4   \t 3.3844e+00 \t1.5942e+00 \t1.7989e-01 \t-8.8618e+00 \t ------- \t ------- \t -----\n",
            "5   \t 3.5249e+00 \t4.7859e-02 \t5.2432e-03 \t-9.1279e+00 \t ------- \t ------- \t -----\n",
            "6   \t 3.5250e+00 \t1.1831e-03 \t1.2649e-04 \t-9.3535e+00 \t ------- \t ------- \t -----\n",
            "7   \t 3.5250e+00 \t6.0994e-07 \t6.5243e-08 \t-9.3487e+00 \t ------- \t ------- \t -----\n",
            "x* =  [0.65873679]\n",
            "Eigenvalues of Hessian at x* =  [-9.34881579+0.j]\n",
            "\n",
            "\n",
            "***Case 8: Quasi-Newton method with BFGS Hessian approximation and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+00 \t6.0000e+00 \t2.0921e+00 \t 1.0000e+00 \t 3.49e-01 \t ------- \t -----\n",
            "1   \t-9.8250e+00 \t8.7067e+00 \t4.3186e-01 \t 7.0297e+00 \t 3.49e-01 \t ------- \t -----\n",
            "2   \t-1.1112e+01 \t1.8607e+00 \t6.8435e-02 \t 2.4470e+01 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t-1.1194e+01 \t5.3331e-01 \t2.4747e-02 \t 1.9396e+01 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t-1.1201e+01 \t2.2697e-02 \t9.9002e-04 \t 2.0633e+01 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t-1.1201e+01 \t1.9264e-03 \t8.2640e-05 \t 2.0980e+01 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t-1.1201e+01 \t1.9144e-04 \t8.2068e-06 \t 2.0995e+01 \t 9.00e-01 \t ------- \t -----\n",
            "7   \t-1.1201e+01 \t1.9134e-05 \t8.2020e-07 \t 2.0996e+01 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [-1.75447795]\n",
            "Eigenvalues of Hessian at x* =  [20.99602496+0.j]\n",
            "\n",
            "\n",
            "***Case 9: Quasi-Newton method with BFGS Hessian approximation and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+00 \t6.0000e+00 \t2.0000e+00 \t 1.0000e+00 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t-1.0500e+01 \t6.0000e+00 \t1.0000e+00 \t 6.0000e+00 \t ------- \t 4.00e+00 \t reject\n",
            "WARNING: Hessian update returned NaN\n",
            "x* =  [-2.]\n",
            "Eigenvalues of Hessian at x* =  [28.+0.j]\n",
            "\n",
            "\n",
            "***Case 10: Steepest Descent and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.5000e+00 \t6.0000e+00 \t2.0921e+00 \t 1.0000e+00 \t 3.49e-01 \t ------- \t -----\n",
            "1   \t-9.8250e+00 \t8.7067e+00 \t4.1010e-01 \t 1.0000e+00 \t 4.71e-02 \t ------- \t -----\n",
            "2   \t-1.1148e+01 \t1.4519e+00 \t9.3812e-02 \t 1.0000e+00 \t 6.46e-02 \t ------- \t -----\n",
            "3   \t-1.1197e+01 \t4.5354e-01 \t2.6373e-02 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "4   \t-1.1201e+01 \t1.0601e-01 \t6.1642e-03 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "5   \t-1.1201e+01 \t2.3088e-02 \t1.3425e-03 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "6   \t-1.1201e+01 \t5.1159e-03 \t2.9749e-04 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "7   \t-1.1201e+01 \t1.1294e-03 \t6.5675e-05 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "8   \t-1.1201e+01 \t2.4954e-04 \t1.4511e-05 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "9   \t-1.1201e+01 \t5.5125e-05 \t3.2055e-06 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "10   \t-1.1201e+01 \t1.2178e-05 \t7.0814e-07 \t 1.0000e+00 \t 5.81e-02 \t ------- \t -----\n",
            "x* =  [-1.75447817]\n",
            "Eigenvalues of Hessian at x* =  [20.99603089+0.j]\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-da651f1b97c6>:36: RuntimeWarning: invalid value encountered in true_divide\n",
            "  dB = -1*xxT(B[k-1].dot(s))/d2 + xxT(y)/sy\n"
          ]
        }
      ],
      "source": [
        "x0 = np.zeros(1)\n",
        "benchmark(x0,f_,df_,ddf_,False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qqJko2LY9A_"
      },
      "source": [
        "#### Discussion\n",
        "\n",
        "Which cases converged to a **local maximizer**?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The cases that the eigen values are negative (the Hessian is negative definit)\n",
        "\n",
        "1- Case 1: Newton method with exact Hessian and no globalization strategy\n",
        "\n",
        "2- Case 2: Newton method with exact Hessian and line search\n",
        "\n",
        "3- Case 3: Newton method with exact Hessian and trust region\n",
        "\n",
        "4- Case 4: Quasi-Newton method with SR1 Hessian approximation and no globalization strategy\n",
        "\n",
        "Which cases converged to a **local minimizer**?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The cases that the eigen values are positive (the Hessian is positive definite)\n",
        "\n",
        "1- Case 5: Quasi-Newton method with SR1 Hessian approximation and line search\n",
        "\n",
        "2- Case 6: Quasi-Newton method with SR1 Hessian approximation and trust region\n",
        "\n",
        "3- Case 7: Quasi-Newton method with BFGS Hessian approximation and no globalization strategy\n",
        "\n",
        "4- Case 8: Quasi-Newton method with BFGS Hessian approximation and line search\n",
        "\n",
        "5- Case 9: Quasi-Newton method with BFGS Hessian approximation and trust region\n",
        "\n",
        "6- Case 10: Steepest Descent and line search\n",
        "\n",
        "Based on these results, which algorithms do you recommend for non-convex problems?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "I think all of these algorithms are not appropriate for the non-convex problems as some of them converge to local minimizer, and some others converge to local maximizer, (they cannot detect both points at the same time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TPq1HZdY9A_"
      },
      "source": [
        "### Return of Example 2.19\n",
        "\n",
        "Now we will benchmark the algorithms using **Example 2.19**.\n",
        "\n",
        "![ex2-19](https://ndcbe.github.io/optimization/_images/ex2-19.png)\n",
        "\n",
        "Consider the function $g(z) = \\sqrt{z}$, which is only defined for $z \\geq 0$. We will shortly learn how handle bounds/inequality constraints in an optimization problem.\n",
        "\n",
        "But for this assignment, we will focus on algorithms for *unconstrained* nonlinear optimization. We will use a smoothed approximation to ensure $g(z)$ is defined and twice-differentiable over $z \\in \\mathbb{R}$. Consider:\n",
        "\n",
        "$$g(z) \\approx \\sqrt{\\max(z,0)}$$\n",
        "\n",
        "This ensures that $g(z)$ is defined over $z \\in \\mathbb{R}$. But what about twice-differentiable? We will further approximate\n",
        "\n",
        "$$\\max(z,0) \\approx \\frac{1}{2}\\left(\\sqrt{z^2 + 10^{-4}} + z \\right)$$\n",
        "\n",
        "Below is an implementation of the Example 2.19 that uses this smoothed approximation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ewCWswNmY9A_"
      },
      "outputs": [],
      "source": [
        "def asqrt(z):\n",
        "    '''\n",
        "    Approximate/smoothed square root\n",
        "    '''\n",
        "\n",
        "    return np.sqrt(0.5*(np.sqrt(z**2 + 1E-4) + z))\n",
        "    \n",
        "def ex2_19_smoothed(x,verbose=False):\n",
        "    ''' Evaluate function given above at point x\n",
        "\n",
        "    Inputs:\n",
        "        x - vector with 2 elements\n",
        "        \n",
        "    Outputs:\n",
        "        f - function value (scalar)\n",
        "    '''\n",
        "    # Constants\n",
        "    a = np.array([0.3, 0.6, 0.2])\n",
        "    b = np.array([5, 26, 3])\n",
        "    c = np.array([40, 1, 10])\n",
        "    \n",
        "    # Intermediates. Recall Python indicies start at 0\n",
        "    u = x[0] - 0.8\n",
        "    s = asqrt(1-u)\n",
        "    s2 = asqrt(1+u)\n",
        "    v = x[1] -(a[0] + a[1]*u**2*s-a[2]*u)\n",
        "    alpha = -b[0] + b[1]*u**2*s2+ b[2]*u\n",
        "    beta = c[0]*v**2*(1-c[1]*v)/(1+c[2]*u**2)\n",
        "    \n",
        "    f = alpha*np.exp(-beta)\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"##### my_f at x = \",x, \"#####\")\n",
        "        print(\"u = \",u)\n",
        "        print(\"sqrt(1-u) = \",s)\n",
        "        print(\"sqrt(1+u) = \",s2)\n",
        "        print(\"v = \",v)\n",
        "        print(\"alpha = \",alpha)\n",
        "        print(\"beta = \",beta)\n",
        "        print(\"f(x) = \",f)\n",
        "        print(\"##### Done. #####\\n\")\n",
        "    \n",
        "    return f\n",
        "\n",
        "my_f2 = lambda x : ex2_19_smoothed(x,verbose=False)\n",
        "\n",
        "my_grad2 = lambda x : my_grad_approx(x,my_f2,1E-6,verbose=False)\n",
        "\n",
        "my_hes2 = lambda x : my_hes_approx(x,my_grad2,1E-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdzZ-6deY9A_"
      },
      "source": [
        "#### Benchmark with $x_0$ Near Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "umJKVsvkY9BA",
        "outputId": "7fc50dae-51d1-4b63-e947-223688cb3ff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Case 1: Newton method with exact Hessian and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t-4.9246e+00 \t1.0874e+01 \t4.1947e-02 \t 4.9370e+01 \t ------- \t ------- \t -----\n",
            "1   \t-5.0888e+00 \t6.2734e-01 \t1.9755e-03 \t 4.2542e+01 \t ------- \t ------- \t -----\n",
            "2   \t-5.0893e+00 \t2.4208e-03 \t3.0022e-05 \t 4.3424e+01 \t ------- \t ------- \t -----\n",
            "3   \t-5.0893e+00 \t2.9175e-07 \t3.1334e-09 \t 4.3418e+01 \t ------- \t ------- \t -----\n",
            "x* =  [0.73950642 0.31435986]\n",
            "Eigenvalues of Hessian at x* =  [ 43.41806155+0.j 426.36193114+0.j]\n",
            "\n",
            "\n",
            "***Case 2: Newton method with exact Hessian and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t-4.9246e+00 \t1.0874e+01 \t3.7752e-02 \t 4.9370e+01 \t 9.00e-01 \t ------- \t -----\n",
            "1   \t-5.0885e+00 \t5.5956e-01 \t4.1718e-03 \t 4.3470e+01 \t 9.00e-01 \t ------- \t -----\n",
            "2   \t-5.0892e+00 \t5.9439e-02 \t4.4430e-04 \t 4.3425e+01 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t-5.0893e+00 \t5.9860e-03 \t4.4750e-05 \t 4.3419e+01 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t-5.0893e+00 \t5.9903e-04 \t4.4783e-06 \t 4.3418e+01 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t-5.0893e+00 \t5.9906e-05 \t4.4784e-07 \t 4.3419e+01 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [0.73950637 0.31435986]\n",
            "Eigenvalues of Hessian at x* =  [ 43.41833229+0.j 426.36188244+0.j]\n",
            "\n",
            "\n",
            "***Case 3: Newton method with exact Hessian and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t-4.9246e+00 \t1.0874e+01 \t4.1947e-02 \t 4.9370e+01 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t-5.0888e+00 \t6.2734e-01 \t1.9755e-03 \t 4.2542e+01 \t ------- \t 2.00e+00 \t accept\n",
            "2   \t-5.0893e+00 \t2.4208e-03 \t3.0022e-05 \t 4.3424e+01 \t ------- \t 2.00e+00 \t accept\n",
            "3   \t-5.0893e+00 \t2.9175e-07 \t3.1334e-09 \t 4.3418e+01 \t ------- \t 2.00e+00 \t reject\n",
            "x* =  [0.73950642 0.31435986]\n",
            "Eigenvalues of Hessian at x* =  [ 43.41820666+0.j 426.36200807+0.j]\n",
            "\n",
            "\n",
            "***Case 4: Quasi-Newton method with SR1 Hessian approximation and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t-4.9246e+00 \t1.0874e+01 \t1.0874e+01 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "Warning: Hessian approximation is near singular.\n",
            "B[k] = \n",
            " [[ 2.40566051e+93 -1.88095467e+93]\n",
            " [-1.88095467e+93  1.47069399e+93]]\n",
            "x* =  [ 5.43705574 10.08833764]\n",
            "Eigenvalues of Hessian at x* =  [ 8.63954930e+95+0.j -6.55410896e+91+0.j]\n",
            "\n",
            "\n",
            "***Case 5: Quasi-Newton method with SR1 Hessian approximation and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t-4.9246e+00 \t1.0874e+01 \t3.3093e-02 \t 1.0000e+00 \t 3.04e-03 \t ------- \t -----\n",
            "1   \t-5.0624e+00 \t3.0234e+00 \t4.1076e-02 \t 1.0000e+00 \t 3.43e-02 \t ------- \t -----\n",
            "2   \t-5.0797e+00 \t2.3380e+00 \t1.2211e-02 \t 3.9331e+01 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t-5.0891e+00 \t2.8838e-01 \t1.3241e-03 \t 3.9320e+01 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t-5.0893e+00 \t2.1938e-02 \t9.6783e-05 \t 3.9598e+01 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t-5.0893e+00 \t2.1508e-03 \t9.3783e-06 \t 3.9642e+01 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t-5.0893e+00 \t2.1418e-04 \t9.4253e-07 \t 3.9642e+01 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [0.73950652 0.31435988]\n",
            "Eigenvalues of Hessian at x* =  [ 43.41820666+0.j 426.36200807+0.j]\n",
            "\n",
            "\n",
            "***Case 6: Quasi-Newton method with SR1 Hessian approximation and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t-4.9246e+00 \t1.0874e+01 \t2.0000e+00 \t 1.0000e+00 \t ------- \t 2.00e+00 \t reject\n",
            "1   \t-4.9246e+00 \t1.0874e+01 \t5.0000e-01 \t 1.0000e+00 \t ------- \t 5.00e-01 \t reject\n",
            "2   \t-4.9246e+00 \t1.0874e+01 \t1.2500e-01 \t 1.0000e+00 \t ------- \t 1.25e-01 \t reject\n",
            "3   \t-4.9246e+00 \t1.0874e+01 \t3.1250e-02 \t 1.0000e+00 \t ------- \t 3.12e-02 \t accept\n",
            "4   \t-5.0665e+00 \t2.3568e+00 \t3.1250e-02 \t 1.0000e+00 \t ------- \t 3.12e-02 \t accept\n",
            "5   \t-5.0881e+00 \t9.8076e-01 \t3.0776e-03 \t 4.0771e+01 \t ------- \t 3.12e-02 \t accept\n",
            "6   \t-5.0892e+00 \t4.6629e-02 \t4.8788e-04 \t 4.4036e+01 \t ------- \t 3.12e-02 \t accept\n",
            "7   \t-5.0893e+00 \t5.4139e-04 \t8.7158e-06 \t 4.3387e+01 \t ------- \t 3.12e-02 \t accept\n",
            "8   \t-5.0893e+00 \t1.7327e-06 \t1.1781e-08 \t 4.3387e+01 \t ------- \t 3.12e-02 \t accept\n",
            "x* =  [0.73950642 0.31435986]\n",
            "Eigenvalues of Hessian at x* =  [ 43.41818718+0.j 426.3618055 +0.j]\n",
            "\n",
            "\n",
            "***Case 7: Quasi-Newton method with BFGS Hessian approximation and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t-4.9246e+00 \t1.0874e+01 \t1.0874e+01 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "Warning: Hessian approximation is near singular.\n",
            "B[k] = \n",
            " [[ 2.40566051e+93 -1.88095467e+93]\n",
            " [-1.88095467e+93  1.47069399e+93]]\n",
            "x* =  [ 5.43705574 10.08833764]\n",
            "Eigenvalues of Hessian at x* =  [ 8.63954930e+95+0.j -6.55410896e+91+0.j]\n",
            "\n",
            "\n",
            "***Case 8: Quasi-Newton method with BFGS Hessian approximation and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t-4.9246e+00 \t1.0874e+01 \t3.3093e-02 \t 1.0000e+00 \t 3.04e-03 \t ------- \t -----\n",
            "1   \t-5.0624e+00 \t3.0234e+00 \t4.1581e-02 \t 9.8785e-01 \t 3.43e-02 \t ------- \t -----\n",
            "2   \t-5.0795e+00 \t2.3319e+00 \t1.2699e-02 \t 3.9367e+01 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t-5.0891e+00 \t2.6985e-01 \t1.2959e-03 \t 3.9562e+01 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t-5.0893e+00 \t2.0328e-02 \t9.3057e-05 \t 3.9888e+01 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t-5.0893e+00 \t1.9879e-03 \t9.0891e-06 \t 3.9910e+01 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t-5.0893e+00 \t1.9866e-04 \t9.0524e-07 \t 3.9919e+01 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [0.73950652 0.31435988]\n",
            "Eigenvalues of Hessian at x* =  [ 43.41879488+0.j 426.36186394+0.j]\n",
            "\n",
            "\n",
            "***Case 9: Quasi-Newton method with BFGS Hessian approximation and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t-4.9246e+00 \t1.0874e+01 \t2.0000e+00 \t 1.0000e+00 \t ------- \t 2.00e+00 \t reject\n",
            "WARNING: Hessian update returned NaN\n",
            "x* =  [0.7 0.3]\n",
            "Eigenvalues of Hessian at x* =  [ 49.36950265+0.j 398.3168298 +0.j]\n",
            "\n",
            "\n",
            "***Case 10: Steepest Descent and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t-4.9246e+00 \t1.0874e+01 \t3.3093e-02 \t 1.0000e+00 \t 3.04e-03 \t ------- \t -----\n",
            "1   \t-5.0624e+00 \t3.0234e+00 \t1.1359e-02 \t 1.0000e+00 \t 3.76e-03 \t ------- \t -----\n",
            "2   \t-5.0738e+00 \t1.8639e+00 \t7.7811e-03 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "3   \t-5.0790e+00 \t1.4471e+00 \t6.7124e-03 \t 1.0000e+00 \t 4.64e-03 \t ------- \t -----\n",
            "4   \t-5.0822e+00 \t1.3118e+00 \t5.4760e-03 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "5   \t-5.0846e+00 \t1.0248e+00 \t4.2781e-03 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "6   \t-5.0862e+00 \t8.0358e-01 \t3.3546e-03 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "7   \t-5.0872e+00 \t6.3360e-01 \t2.9389e-03 \t 1.0000e+00 \t 4.64e-03 \t ------- \t -----\n",
            "8   \t-5.0879e+00 \t5.7714e-01 \t2.4093e-03 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "9   \t-5.0883e+00 \t4.5474e-01 \t1.8983e-03 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "10   \t-5.0886e+00 \t3.5893e-01 \t1.4984e-03 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "11   \t-5.0889e+00 \t2.8408e-01 \t1.3177e-03 \t 1.0000e+00 \t 4.64e-03 \t ------- \t -----\n",
            "12   \t-5.0890e+00 \t2.5979e-01 \t1.0845e-03 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "13   \t-5.0891e+00 \t2.0513e-01 \t8.5631e-04 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-da651f1b97c6>:36: RuntimeWarning: invalid value encountered in true_divide\n",
            "  dB = -1*xxT(B[k-1].dot(s))/d2 + xxT(y)/sy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14   \t-5.0891e+00 \t1.6217e-01 \t6.7697e-04 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "15   \t-5.0892e+00 \t1.2843e-01 \t5.3612e-04 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "16   \t-5.0892e+00 \t1.0183e-01 \t4.7234e-04 \t 1.0000e+00 \t 4.64e-03 \t ------- \t -----\n",
            "17   \t-5.0892e+00 \t9.3123e-02 \t3.8875e-04 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "18   \t-5.0892e+00 \t7.3619e-02 \t3.0732e-04 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "19   \t-5.0892e+00 \t5.8276e-02 \t2.4328e-04 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "20   \t-5.0892e+00 \t4.6182e-02 \t1.9279e-04 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "21   \t-5.0892e+00 \t3.6644e-02 \t1.6997e-04 \t 1.0000e+00 \t 4.64e-03 \t ------- \t -----\n",
            "22   \t-5.0893e+00 \t3.3525e-02 \t1.3995e-04 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "23   \t-5.0893e+00 \t2.6516e-02 \t1.1069e-04 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "24   \t-5.0893e+00 \t2.0994e-02 \t8.7642e-05 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "25   \t-5.0893e+00 \t1.6641e-02 \t6.9468e-05 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "26   \t-5.0893e+00 \t1.3205e-02 \t6.1248e-05 \t 1.0000e+00 \t 4.64e-03 \t ------- \t -----\n",
            "27   \t-5.0893e+00 \t1.2088e-02 \t5.0461e-05 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "28   \t-5.0893e+00 \t9.5608e-03 \t3.9912e-05 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "29   \t-5.0893e+00 \t7.5698e-03 \t3.1601e-05 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "30   \t-5.0893e+00 \t5.9997e-03 \t2.5046e-05 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "31   \t-5.0893e+00 \t4.7605e-03 \t2.2081e-05 \t 1.0000e+00 \t 4.64e-03 \t ------- \t -----\n",
            "32   \t-5.0893e+00 \t4.3607e-03 \t1.8204e-05 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "33   \t-5.0893e+00 \t3.4488e-03 \t1.4397e-05 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "34   \t-5.0893e+00 \t2.7303e-03 \t1.1398e-05 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "35   \t-5.0893e+00 \t2.1638e-03 \t9.0327e-06 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "36   \t-5.0893e+00 \t1.7166e-03 \t7.9622e-06 \t 1.0000e+00 \t 4.64e-03 \t ------- \t -----\n",
            "37   \t-5.0893e+00 \t1.5735e-03 \t6.5685e-06 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "38   \t-5.0893e+00 \t1.2443e-03 \t5.1943e-06 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "39   \t-5.0893e+00 \t9.8491e-04 \t4.1116e-06 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "40   \t-5.0893e+00 \t7.8042e-04 \t3.2579e-06 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "41   \t-5.0893e+00 \t6.1904e-04 \t2.8713e-06 \t 1.0000e+00 \t 4.64e-03 \t ------- \t -----\n",
            "42   \t-5.0893e+00 \t5.6781e-04 \t2.3703e-06 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "43   \t-5.0893e+00 \t4.4894e-04 \t1.8741e-06 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "44   \t-5.0893e+00 \t3.5531e-04 \t1.4833e-06 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "45   \t-5.0893e+00 \t2.8149e-04 \t1.1751e-06 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "46   \t-5.0893e+00 \t2.2325e-04 \t1.0355e-06 \t 1.0000e+00 \t 4.64e-03 \t ------- \t -----\n",
            "47   \t-5.0893e+00 \t2.0491e-04 \t8.5540e-07 \t 1.0000e+00 \t 4.17e-03 \t ------- \t -----\n",
            "x* =  [0.73950441 0.31436015]\n",
            "Eigenvalues of Hessian at x* =  [ 43.41854262+0.j 426.36145006+0.j]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "x0 = np.array([0.7, 0.3])\n",
        "benchmark(x0,my_f2,my_grad2,my_hes2,False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3Hrsi8-Y9BA"
      },
      "source": [
        "#### Discussion\n",
        "\n",
        "Which cases do not converge to the known solution?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "1- Case 4: Quasi-Newton method with SR1 Hessian approximation and no globalization strategy\n",
        "\n",
        "2- Case 7: Quasi-Newton method with BFGS Hessian approximation and no globalization strategy\n",
        "\n",
        "What is happening with the SR1 and BFGS update when no globalization strategy is used? *Hint:* This is related to the square root approximation.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "In these two cases the Hessian is near singular which means that the denominator in both cases are ill conditiones (In other word, as we have to calculate the inverse of Hessian, by having the results that are near zero (Singular), we will converge to the wrong solutions.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Dl9c9kY9BA"
      },
      "source": [
        "#### Benchmark with $x_0$ Far From the Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "S8WvA82zY9BA",
        "outputId": "85b2daa1-0965-46c3-dd39-a8baf2ef4b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Case 1: Newton method with exact Hessian and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.7116e-06 \t1.5723e-04 \t3.8594e-02 \t-2.9410e-03 \t ------- \t ------- \t -----\n",
            "1   \t 5.7117e-07 \t5.5951e-05 \t3.6202e-02 \t-1.0859e-03 \t ------- \t ------- \t -----\n",
            "2   \t 1.9240e-07 \t1.9977e-05 \t3.4172e-02 \t-4.0313e-04 \t ------- \t ------- \t -----\n",
            "3   \t 6.5310e-08 \t7.1521e-06 \t3.2420e-02 \t-1.5022e-04 \t ------- \t ------- \t -----\n",
            "4   \t 2.2312e-08 \t2.5663e-06 \t3.0889e-02 \t-5.6123e-05 \t ------- \t ------- \t -----\n",
            "5   \t 7.6638e-09 \t9.2257e-07 \t2.9536e-02 \t-2.1007e-05 \t ------- \t ------- \t -----\n",
            "x* =  [-0.00313327 -0.20178781]\n",
            "Eigenvalues of Hessian at x* =  [ 1.45576349e-05+0.j -7.87341659e-06+0.j]\n",
            "\n",
            "\n",
            "***Case 2: Newton method with exact Hessian and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.7116e-06 \t1.5723e-04 \t3.4734e-02 \t-2.9410e-03 \t 9.00e-01 \t ------- \t -----\n",
            "1   \t 6.3940e-07 \t6.2229e-05 \t3.2787e-02 \t-1.2030e-03 \t 9.00e-01 \t ------- \t -----\n",
            "2   \t 2.4063e-07 \t2.4689e-05 \t3.1108e-02 \t-4.9417e-04 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t 9.1115e-08 \t9.8155e-06 \t2.9641e-02 \t-2.0360e-04 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t 3.4682e-08 \t3.9088e-06 \t2.8345e-02 \t-8.4068e-05 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t 1.3260e-08 \t1.5589e-06 \t2.7189e-02 \t-3.4766e-05 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t 5.0896e-09 \t6.2249e-07 \t2.6149e-02 \t-1.4393e-05 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [-0.00322675 -0.2099284 ]\n",
            "Eigenvalues of Hessian at x* =  [ 1.10303078e-05+0.j -5.96383638e-06+0.j]\n",
            "\n",
            "\n",
            "***Case 3: Newton method with exact Hessian and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.7116e-06 \t1.5723e-04 \t3.8594e-02 \t-2.9410e-03 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t 5.7117e-07 \t5.5951e-05 \t3.6202e-02 \t-1.0859e-03 \t ------- \t 2.00e+00 \t accept\n",
            "2   \t 1.9240e-07 \t1.9977e-05 \t3.4172e-02 \t-4.0313e-04 \t ------- \t 2.00e+00 \t accept\n",
            "3   \t 6.5310e-08 \t7.1521e-06 \t3.2420e-02 \t-1.5022e-04 \t ------- \t 2.00e+00 \t accept\n",
            "4   \t 2.2312e-08 \t2.5663e-06 \t3.0889e-02 \t-5.6123e-05 \t ------- \t 2.00e+00 \t accept\n",
            "5   \t 7.6638e-09 \t9.2257e-07 \t2.9536e-02 \t-2.1007e-05 \t ------- \t 2.00e+00 \t accept\n",
            "x* =  [-0.00313327 -0.20178781]\n",
            "Eigenvalues of Hessian at x* =  [ 1.45576349e-05+0.j -7.87341659e-06+0.j]\n",
            "\n",
            "\n",
            "***Case 4: Quasi-Newton method with SR1 Hessian approximation and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.7116e-06 \t1.5723e-04 \t1.5723e-04 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "1   \t 1.6869e-06 \t1.5677e-04 \t5.3086e-02 \t 2.9530e-03 \t ------- \t ------- \t -----\n",
            "2   \t-2.3989e-06 \t7.2336e-05 \t4.0934e-03 \t 2.7417e-03 \t ------- \t ------- \t -----\n",
            "3   \t-2.4364e-06 \t7.1078e-05 \t3.7770e-03 \t 1.5844e-03 \t ------- \t ------- \t -----\n",
            "4   \t-2.4551e-06 \t7.0156e-05 \t1.6393e-03 \t 1.4153e-03 \t ------- \t ------- \t -----\n",
            "5   \t-2.4788e-06 \t7.0331e-05 \t7.1786e-02 \t 8.7441e-04 \t ------- \t ------- \t -----\n",
            "6   \t-1.3803e-05 \t3.5715e-04 \t7.7165e-02 \t-4.7635e-03 \t ------- \t ------- \t -----\n",
            "7   \t-1.8335e-06 \t5.2108e-05 \t1.2853e-02 \t-4.0717e-03 \t ------- \t ------- \t -----\n",
            "8   \t-1.2703e-06 \t3.6881e-05 \t3.1009e-02 \t-1.1894e-03 \t ------- \t ------- \t -----\n",
            "9   \t-5.0534e-07 \t1.5390e-05 \t2.2172e-02 \t-6.9356e-04 \t ------- \t ------- \t -----\n",
            "10   \t-2.5506e-07 \t8.0241e-06 \t2.4104e-02 \t-3.3191e-04 \t ------- \t ------- \t -----\n",
            "11   \t-1.1847e-07 \t3.8571e-06 \t2.2260e-02 \t-1.7236e-04 \t ------- \t ------- \t -----\n",
            "12   \t-5.7063e-08 \t1.9164e-06 \t2.1932e-02 \t-8.6740e-05 \t ------- \t ------- \t -----\n",
            "13   \t-2.7199e-08 \t9.4119e-07 \t2.1123e-02 \t-4.4158e-05 \t ------- \t ------- \t -----\n",
            "x* =  [-0.08873597 -0.1844557 ]\n",
            "Eigenvalues of Hessian at x* =  [ 3.41425782e-06+0.j -1.58483086e-05+0.j]\n",
            "\n",
            "\n",
            "***Case 5: Quasi-Newton method with SR1 Hessian approximation and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.7116e-06 \t1.5723e-04 \t1.4151e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "1   \t 1.6894e-06 \t1.5681e-04 \t4.7799e-02 \t 2.9526e-03 \t 9.00e-01 \t ------- \t -----\n",
            "2   \t-2.3151e-06 \t7.4485e-05 \t6.5858e-03 \t 2.8451e-03 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t-2.4172e-06 \t7.2023e-05 \t4.9746e-03 \t 1.7776e-03 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t-2.4520e-06 \t7.0610e-05 \t1.9853e-03 \t 1.5094e-03 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t-2.4642e-06 \t7.0284e-05 \t3.4800e-03 \t 1.3731e-03 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "6   \t-2.5883e-06 \t7.2796e-05 \t4.0455e-02 \t-1.6195e-03 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "7   \t-7.9295e-07 \t2.4312e-05 \t1.8111e-02 \t-1.2048e-03 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "8   \t-4.6187e-07 \t1.4536e-05 \t2.4223e-02 \t-5.3035e-04 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "9   \t-2.1937e-07 \t7.1480e-06 \t2.1069e-02 \t-2.9720e-04 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "10   \t-1.1246e-07 \t3.7760e-06 \t2.1203e-02 \t-1.5490e-04 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "11   \t-5.6288e-08 \t1.9476e-06 \t2.0287e-02 \t-8.3104e-05 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "12   \t-2.8485e-08 \t1.0143e-06 \t1.9793e-02 \t-4.4204e-05 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "13   \t-1.4393e-08 \t5.2699e-07 \t1.9211e-02 \t-2.3601e-05 \t 9.00e-01 \t ------- \t -----\n",
            "x* =  [-0.04837776 -0.19925516]\n",
            "Eigenvalues of Hessian at x* =  [ 6.02290594e-06+0.j -9.54318645e-06+0.j]\n",
            "\n",
            "\n",
            "***Case 6: Quasi-Newton method with SR1 Hessian approximation and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.7116e-06 \t1.5723e-04 \t1.5723e-04 \t 1.0000e+00 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t 1.6869e-06 \t1.5677e-04 \t5.3086e-02 \t 2.9530e-03 \t ------- \t 2.00e+00 \t accept\n",
            "2   \t-2.3989e-06 \t7.2336e-05 \t4.0934e-03 \t 2.7417e-03 \t ------- \t 2.00e+00 \t accept\n",
            "3   \t-2.4364e-06 \t7.1078e-05 \t3.7770e-03 \t 1.5844e-03 \t ------- \t 2.00e+00 \t accept\n",
            "4   \t-2.4551e-06 \t7.0156e-05 \t1.6393e-03 \t 1.4153e-03 \t ------- \t 2.00e+00 \t accept\n",
            "5   \t-2.4788e-06 \t7.0331e-05 \t7.1786e-02 \t 8.7441e-04 \t ------- \t 2.00e+00 \t accept\n",
            "6   \t-1.3803e-05 \t3.5715e-04 \t7.7165e-02 \t-4.7635e-03 \t ------- \t 2.00e+00 \t accept\n",
            "7   \t-1.8335e-06 \t5.2108e-05 \t1.2853e-02 \t-4.0717e-03 \t ------- \t 2.00e+00 \t accept\n",
            "8   \t-1.2703e-06 \t3.6881e-05 \t3.1009e-02 \t-1.1894e-03 \t ------- \t 2.00e+00 \t accept\n",
            "9   \t-5.0534e-07 \t1.5390e-05 \t2.2172e-02 \t-6.9356e-04 \t ------- \t 2.00e+00 \t accept\n",
            "10   \t-2.5506e-07 \t8.0241e-06 \t2.4104e-02 \t-3.3191e-04 \t ------- \t 2.00e+00 \t accept\n",
            "11   \t-1.1847e-07 \t3.8571e-06 \t2.2260e-02 \t-1.7236e-04 \t ------- \t 2.00e+00 \t accept\n",
            "12   \t-5.7063e-08 \t1.9164e-06 \t2.1932e-02 \t-8.6740e-05 \t ------- \t 2.00e+00 \t accept\n",
            "13   \t-2.7199e-08 \t9.4119e-07 \t2.1123e-02 \t-4.4158e-05 \t ------- \t 2.00e+00 \t accept\n",
            "x* =  [-0.08873597 -0.1844557 ]\n",
            "Eigenvalues of Hessian at x* =  [ 3.41425782e-06+0.j -1.58483086e-05+0.j]\n",
            "\n",
            "\n",
            "***Case 7: Quasi-Newton method with BFGS Hessian approximation and no globalization strategy***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.7116e-06 \t1.5723e-04 \t1.5723e-04 \t 1.0000e+00 \t ------- \t ------- \t -----\n",
            "1   \t 1.6869e-06 \t1.5677e-04 \t5.3086e-02 \t 2.9531e-03 \t ------- \t ------- \t -----\n",
            "2   \t-2.3988e-06 \t7.2335e-05 \t4.0930e-03 \t 2.7417e-03 \t ------- \t ------- \t -----\n",
            "3   \t-2.4363e-06 \t7.1075e-05 \t3.7674e-03 \t 1.5843e-03 \t ------- \t ------- \t -----\n",
            "4   \t-2.4541e-06 \t7.0132e-05 \t1.4838e-03 \t 1.4144e-03 \t ------- \t ------- \t -----\n",
            "5   \t-2.4625e-06 \t6.9939e-05 \t3.5609e-03 \t 1.3206e-03 \t ------- \t ------- \t -----\n",
            "6   \t-2.4925e-06 \t7.0002e-05 \t5.2444e-03 \t 1.2277e-03 \t ------- \t ------- \t -----\n",
            "7   \t-2.5590e-06 \t7.1224e-05 \t1.0363e-02 \t 1.0463e-03 \t ------- \t ------- \t -----\n",
            "8   \t-2.7434e-06 \t7.6225e-05 \t2.1814e-02 \t 7.5609e-04 \t ------- \t ------- \t -----\n",
            "9   \t-3.2424e-06 \t9.2100e-05 \t5.8241e-02 \t 4.0477e-04 \t ------- \t ------- \t -----\n",
            "10   \t-4.8073e-06 \t1.4577e-04 \t2.1018e-01 \t 1.4269e-04 \t ------- \t ------- \t -----\n",
            "11   \t-1.9628e-06 \t9.4281e-05 \t9.6161e-02 \t 2.9352e-04 \t ------- \t ------- \t -----\n",
            "12   \t-8.3748e-06 \t3.5280e-04 \t1.3118e-01 \t-2.6458e-03 \t ------- \t ------- \t -----\n",
            "13   \t-8.5570e-07 \t4.3243e-05 \t1.8941e-02 \t-2.1072e-03 \t ------- \t ------- \t -----\n",
            "14   \t-5.1941e-07 \t2.7004e-05 \t3.2617e-02 \t-5.4552e-04 \t ------- \t ------- \t -----\n",
            "15   \t-2.0475e-07 \t1.1188e-05 \t2.4064e-02 \t-2.8675e-04 \t ------- \t ------- \t -----\n",
            "16   \t-9.7525e-08 \t5.5321e-06 \t2.4405e-02 \t-1.3436e-04 \t ------- \t ------- \t -----\n",
            "17   \t-4.3867e-08 \t2.5855e-06 \t2.2151e-02 \t-6.8649e-05 \t ------- \t ------- \t -----\n",
            "18   \t-2.0384e-08 \t1.2443e-06 \t2.1178e-02 \t-3.4638e-05 \t ------- \t ------- \t -----\n",
            "19   \t-9.4345e-09 \t5.9565e-07 \t1.9986e-02 \t-1.7707e-05 \t ------- \t ------- \t -----\n",
            "x* =  [-0.49035547  0.2432315 ]\n",
            "Eigenvalues of Hessian at x* =  [-1.80821195e-05+0.j  9.13814416e-08+0.j]\n",
            "\n",
            "\n",
            "***Case 8: Quasi-Newton method with BFGS Hessian approximation and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.7116e-06 \t1.5723e-04 \t1.4151e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "1   \t 1.6894e-06 \t1.5681e-04 \t4.7799e-02 \t 2.9526e-03 \t 9.00e-01 \t ------- \t -----\n",
            "2   \t-2.3150e-06 \t7.4484e-05 \t6.5848e-03 \t 2.8452e-03 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t-2.4170e-06 \t7.2018e-05 \t4.9648e-03 \t 1.7776e-03 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t-2.4513e-06 \t7.0596e-05 \t1.9394e-03 \t 1.5092e-03 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t-2.4601e-06 \t7.0192e-05 \t2.0919e-03 \t 1.3696e-03 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t-2.4728e-06 \t6.9985e-05 \t3.3009e-03 \t 1.3002e-03 \t 9.00e-01 \t ------- \t -----\n",
            "7   \t-2.5027e-06 \t7.0170e-05 \t5.5040e-03 \t 1.1977e-03 \t 9.00e-01 \t ------- \t -----\n",
            "8   \t-2.5750e-06 \t7.1604e-05 \t9.9927e-03 \t 1.0172e-03 \t 9.00e-01 \t ------- \t -----\n",
            "9   \t-2.7548e-06 \t7.6565e-05 \t2.0609e-02 \t 7.3654e-04 \t 9.00e-01 \t ------- \t -----\n",
            "10   \t-3.2233e-06 \t9.1493e-05 \t5.1172e-02 \t 4.0986e-04 \t 9.00e-01 \t ------- \t -----\n",
            "11   \t-4.5812e-06 \t1.3804e-04 \t1.0727e-01 \t 1.6089e-04 \t 5.90e-01 \t ------- \t -----\n",
            "12   \t-6.4488e-06 \t2.7075e-04 \t3.9694e-02 \t 7.0623e-04 \t 9.00e-01 \t ------- \t -----\n",
            "13   \t-1.0718e-05 \t3.1817e-04 \t1.2696e-01 \t 1.3728e-03 \t 9.00e-01 \t ------- \t -----\n",
            "14   \t-1.0426e-04 \t2.3308e-03 \t5.6827e-01 \t-6.7478e-02 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "15   \t-1.3721e+00 \t1.7120e+01 \t5.0284e-01 \t-4.7473e+01 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "16   \t 8.9708e-06 \t3.2472e-03 \t2.1036e-02 \t-5.2725e+01 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "17   \t 5.6507e-05 \t2.9250e-03 \t3.3729e-02 \t-5.2692e+01 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "18   \t 8.0322e-05 \t1.7407e-03 \t6.2082e-03 \t-5.2614e+01 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "19   \t 8.1751e-05 \t1.9699e-03 \t1.0920e-04 \t-5.1747e+01 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "20   \t 8.1819e-05 \t1.9747e-03 \t2.0658e-02 \t-8.2545e-01 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "21   \t 9.6335e-05 \t3.0868e-03 \t2.9116e-02 \t-8.4357e-01 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "22   \t 1.1836e-04 \t5.3834e-03 \t6.9289e-02 \t-9.3188e-01 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "23   \t 1.7026e-04 \t1.7960e-02 \t1.0397e-01 \t-1.8703e+00 \t 9.00e-01 \t ------- \t -----\n",
            "24   \t 6.8408e-04 \t8.8589e-02 \t1.2449e-01 \t-4.8324e-03 \t 9.00e-01 \t ------- \t -----\n",
            "The algorithm failed as the Goldstein criteria does not meet!\n",
            "The algorithm failed as the Armijo criteria does not meet!\n",
            "25   \t-5.6721e-03 \t4.0703e-01 \t8.9942e-02 \t-7.4954e+00 \t 9.00e-01 \t ------- \t -----\n",
            "26   \t 2.1837e-02 \t1.6666e-01 \t1.8026e+00 \t-2.3671e+01 \t 2.06e-01 \t ------- \t -----\n",
            "Warning: Hessian approximation is near singular.\n",
            "B[k] = \n",
            " [[-7.81718362e+36  7.35348867e+36]\n",
            " [ 7.35348867e+36 -6.91729889e+36]]\n",
            "x* =  [0.96413342 2.06095958]\n",
            "Eigenvalues of Hessian at x* =  [-1.54474241e+39+0.j  1.07566169e+37+0.j]\n",
            "\n",
            "\n",
            "***Case 9: Quasi-Newton method with BFGS Hessian approximation and trust region***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.7116e-06 \t1.5723e-04 \t1.5723e-04 \t 1.0000e+00 \t ------- \t 2.00e+00 \t accept\n",
            "1   \t 1.6869e-06 \t1.5677e-04 \t5.3086e-02 \t 2.9531e-03 \t ------- \t 2.00e+00 \t accept\n",
            "2   \t-2.3988e-06 \t7.2335e-05 \t4.0930e-03 \t 2.7417e-03 \t ------- \t 2.00e+00 \t accept\n",
            "3   \t-2.4363e-06 \t7.1075e-05 \t3.7674e-03 \t 1.5843e-03 \t ------- \t 2.00e+00 \t accept\n",
            "4   \t-2.4541e-06 \t7.0132e-05 \t1.4838e-03 \t 1.4144e-03 \t ------- \t 2.00e+00 \t accept\n",
            "5   \t-2.4625e-06 \t6.9939e-05 \t3.5609e-03 \t 1.3206e-03 \t ------- \t 2.00e+00 \t accept\n",
            "6   \t-2.4925e-06 \t7.0002e-05 \t5.2444e-03 \t 1.2277e-03 \t ------- \t 2.00e+00 \t accept\n",
            "7   \t-2.5590e-06 \t7.1224e-05 \t1.0363e-02 \t 1.0463e-03 \t ------- \t 2.00e+00 \t accept\n",
            "8   \t-2.7434e-06 \t7.6225e-05 \t2.1814e-02 \t 7.5609e-04 \t ------- \t 2.00e+00 \t accept\n",
            "9   \t-3.2424e-06 \t9.2100e-05 \t5.8241e-02 \t 4.0477e-04 \t ------- \t 2.00e+00 \t accept\n",
            "10   \t-4.8073e-06 \t1.4577e-04 \t2.1018e-01 \t 1.4269e-04 \t ------- \t 2.00e+00 \t reject\n",
            "WARNING: Hessian update returned NaN\n",
            "x* =  [-0.14814336  0.02501684]\n",
            "Eigenvalues of Hessian at x* =  [ 0.00034274+0.j -0.00411974+0.j]\n",
            "\n",
            "\n",
            "***Case 10: Steepest Descent and line search***\n",
            "Iter. \tf(x) \t\t||grad(x)|| \t||p|| \t\tmin(eig(B)) \talpha \t\tdelta \t\tstep\n",
            "0   \t 1.7116e-06 \t1.5723e-04 \t1.4151e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "1   \t 1.6894e-06 \t1.5681e-04 \t1.4113e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "2   \t 1.6673e-06 \t1.5640e-04 \t1.4076e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "3   \t 1.6453e-06 \t1.5598e-04 \t1.4038e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "4   \t 1.6234e-06 \t1.5557e-04 \t1.4002e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "5   \t 1.6017e-06 \t1.5516e-04 \t1.3965e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "6   \t 1.5800e-06 \t1.5476e-04 \t1.3928e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "7   \t 1.5585e-06 \t1.5436e-04 \t1.3892e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "8   \t 1.5371e-06 \t1.5396e-04 \t1.3856e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "9   \t 1.5158e-06 \t1.5356e-04 \t1.3820e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "10   \t 1.4946e-06 \t1.5317e-04 \t1.3785e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "11   \t 1.4735e-06 \t1.5277e-04 \t1.3750e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "12   \t 1.4525e-06 \t1.5239e-04 \t1.3715e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "13   \t 1.4317e-06 \t1.5200e-04 \t1.3680e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "14   \t 1.4109e-06 \t1.5162e-04 \t1.3645e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "15   \t 1.3902e-06 \t1.5123e-04 \t1.3611e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "16   \t 1.3697e-06 \t1.5086e-04 \t1.3577e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "17   \t 1.3492e-06 \t1.5048e-04 \t1.3543e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "18   \t 1.3289e-06 \t1.5011e-04 \t1.3510e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "19   \t 1.3086e-06 \t1.4974e-04 \t1.3476e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "20   \t 1.2885e-06 \t1.4937e-04 \t1.3443e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "21   \t 1.2684e-06 \t1.4900e-04 \t1.3410e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "22   \t 1.2484e-06 \t1.4864e-04 \t1.3378e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "23   \t 1.2286e-06 \t1.4828e-04 \t1.3345e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "24   \t 1.2088e-06 \t1.4792e-04 \t1.3313e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "25   \t 1.1892e-06 \t1.4757e-04 \t1.3281e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "26   \t 1.1696e-06 \t1.4721e-04 \t1.3249e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "27   \t 1.1501e-06 \t1.4686e-04 \t1.3218e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "28   \t 1.1307e-06 \t1.4651e-04 \t1.3186e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "29   \t 1.1114e-06 \t1.4617e-04 \t1.3155e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "30   \t 1.0922e-06 \t1.4582e-04 \t1.3124e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "31   \t 1.0731e-06 \t1.4548e-04 \t1.3094e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "32   \t 1.0541e-06 \t1.4515e-04 \t1.3063e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "33   \t 1.0351e-06 \t1.4481e-04 \t1.3033e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "34   \t 1.0163e-06 \t1.4448e-04 \t1.3003e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "35   \t 9.9751e-07 \t1.4414e-04 \t1.2973e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "36   \t 9.7883e-07 \t1.4382e-04 \t1.2943e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "37   \t 9.6024e-07 \t1.4349e-04 \t1.2914e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "38   \t 9.4173e-07 \t1.4317e-04 \t1.2885e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "39   \t 9.2330e-07 \t1.4284e-04 \t1.2856e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "40   \t 9.0496e-07 \t1.4253e-04 \t1.2827e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "41   \t 8.8670e-07 \t1.4221e-04 \t1.2799e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "42   \t 8.6852e-07 \t1.4189e-04 \t1.2770e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "43   \t 8.5041e-07 \t1.4158e-04 \t1.2742e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "44   \t 8.3239e-07 \t1.4127e-04 \t1.2714e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "45   \t 8.1445e-07 \t1.4096e-04 \t1.2687e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "46   \t 7.9659e-07 \t1.4066e-04 \t1.2659e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "47   \t 7.7880e-07 \t1.4036e-04 \t1.2632e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "48   \t 7.6109e-07 \t1.4006e-04 \t1.2605e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "49   \t 7.4345e-07 \t1.3976e-04 \t1.2578e-04 \t 1.0000e+00 \t 9.00e-01 \t ------- \t -----\n",
            "Reached maximum number of iterations.\n",
            "x* =  [-0.00650146 -0.00141603]\n",
            "Eigenvalues of Hessian at x* =  [ 0.00455505+0.j -0.00270007+0.j]\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-da651f1b97c6>:36: RuntimeWarning: invalid value encountered in true_divide\n",
            "  dB = -1*xxT(B[k-1].dot(s))/d2 + xxT(y)/sy\n"
          ]
        }
      ],
      "source": [
        "x0 = np.array([0.0, 0.0])\n",
        "benchmark(x0,my_f2,my_grad2,my_hes2,False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SquFldWiY9BA"
      },
      "source": [
        "#### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfDvBDW5Y9BA"
      },
      "source": [
        "Did any of the 10 cases converge to the known solution?\n",
        "\n",
        "The first three cases seems to converge to the known points\n",
        "\n",
        "\n",
        "What do you recommend trying next to more reliably solve this particular problem?\n",
        "\n",
        "1- Changing the algoritms\n",
        "\n",
        "2-use a better solver (ipopt)\n",
        "\n",
        "3- If we have the prior knowledge, include it to the optimization problem (initial guesses.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yAZw6fYwY9BB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}